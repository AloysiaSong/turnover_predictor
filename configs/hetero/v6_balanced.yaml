# Configuration for GNN v6 BALANCED - Best of Both Worlds
# =========================================================
# Goal: Balance Turnover F1 and Preference Accuracy
#
# Key changes from v6_optimized:
# - Increased alpha (turnover weight): 0.2 → 0.4
# - Decreased beta (preference weight): 0.8 → 0.6
# - Moderate focal loss: alpha=0.30, gamma=2.2
# - Keep hard negative improvements (0.85 ratio, cache 10)
# - Use concat mode (better for turnover prediction)

seed: 42
device: auto

data:
  graph_path: data/processed/hetero_graph.pt
  triples_path: data/processed/preference_triples.pt
  scaler_path: data/processed/feature_scaler.pkl

model:
  hidden_dim: 128
  num_layers: 2
  heads: 4
  dropout: 0.2
  use_layernorm: true

training:
  weight_decay: 0.0005
  grad_clip: 1.0

  # Stage 1: Pre-train on Turnover task
  stage1:
    epochs: 150
    patience: 20
    lr: 0.001

  # Stage 2: Balanced multi-task fine-tuning
  stage2:
    epochs: 200
    patience: 25
    lr: 0.0005
    freeze_layers: 0

    # ⚖️ BALANCED task weights
    alpha: 0.4           # ⬆️ Increased turnover weight (was 0.2)
    beta: 0.6            # ⬇️ Decreased preference weight (was 0.8)

    # Hard negative sampling (keep P0 improvements)
    hard_ratio: 0.85
    cache_size: 10
    update_freq: 5

loss:
  # ⚖️ BALANCED focal loss parameters
  turnover:
    loss_type: focal
    alpha: 0.30          # Moderate positive weight
    gamma: 2.2           # Moderate hard sample focus
    pos_weight: null

  # Preference ranking loss
  preference:
    loss_type: adaptive_margin
    margin: 1.0
    max_margin: 3.0
    margin_growth: 0.1
    ranking_weight: 0.1
    hard_negative_weight: 2.0

  # Use concat mode for better feature interaction
  preference_head:
    hidden_dim: 128
    dropout: 0.3
    mode: concat         # Richer feature interaction

logging:
  save_dir: outputs/hetero_v6_balanced
