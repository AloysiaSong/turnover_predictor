# GNNæ¨¡å‹å¯è§£é‡Šæ€§æŒ‡å—

**ç‰ˆæœ¬**: 1.0
**æ—¥æœŸ**: 2025-10-19
**ç›®çš„**: è§£é‡Š"ä¸ºä»€ä¹ˆè¯¥å‘˜å·¥è¢«åˆ¤ä¸ºé«˜é£é™©"

---

## ğŸ“‹ ç›®å½•

1. [æ¦‚è¿°](#æ¦‚è¿°)
2. [è§£é‡Šæ–¹æ³•](#è§£é‡Šæ–¹æ³•)
3. [ä½¿ç”¨æŒ‡å—](#ä½¿ç”¨æŒ‡å—)
4. [ç¤ºä¾‹åˆ†æ](#ç¤ºä¾‹åˆ†æ)
5. [æŠ€æœ¯ç»†èŠ‚](#æŠ€æœ¯ç»†èŠ‚)
6. [æœªæ¥æ‰©å±•](#æœªæ¥æ‰©å±•)

---

## æ¦‚è¿°

### ä¸ºä»€ä¹ˆéœ€è¦å¯è§£é‡Šæ€§?

åœ¨å‘˜å·¥ç¦»èŒé¢„æµ‹åœºæ™¯ä¸­,ä»…æä¾›"è¯¥å‘˜å·¥ç¦»èŒé£é™©é«˜"æ˜¯ä¸å¤Ÿçš„,æˆ‘ä»¬éœ€è¦å›ç­”:

1. **ä¸ºä»€ä¹ˆ**è¿™ä¸ªå‘˜å·¥è¢«åˆ¤ä¸ºé«˜é£é™©?
2. **å“ªäº›ç‰¹å¾**å¯¹é¢„æµ‹è´¡çŒ®æœ€å¤§?
3. **å“ªäº›å…³ç³»**(å›¾ç»“æ„)å½±å“äº†é¢„æµ‹?
4. **åå¥½æ¨è**çš„ç†ç”±æ˜¯ä»€ä¹ˆ?

### æˆ‘ä»¬çš„è§£é‡Šæ¡†æ¶

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                  GNNå¯è§£é‡Šæ€§æ¡†æ¶                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                               â”‚
â”‚  1. ç‰¹å¾çº§è´¡çŒ® (Feature-Level)                               â”‚
â”‚     â†’ å“ªäº›å‘˜å·¥ç‰¹å¾å¢åŠ /é™ä½ç¦»èŒé£é™©?                          â”‚
â”‚     â†’ çº¿æ€§æƒé‡åˆ†è§£                                            â”‚
â”‚                                                               â”‚
â”‚  2. å›¾ç»“æ„è´¡çŒ® (Neighbor-Level)                              â”‚
â”‚     â†’ å“ªäº›å²—ä½/å…¬å¸å…³ç³»å½±å“é¢„æµ‹?                              â”‚
â”‚     â†’ æ³¨æ„åŠ›æƒé‡åˆ†æ                                          â”‚
â”‚                                                               â”‚
â”‚  3. åå¥½è§£é‡Š (Preference)                                    â”‚
â”‚     â†’ ä¸ºä»€ä¹ˆå‘˜å·¥åå¥½å²—ä½Aèƒœè¿‡å²—ä½B?                           â”‚
â”‚     â†’ Pairwiseåˆ†æ•°å¯¹æ¯”                                        â”‚
â”‚                                                               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## è§£é‡Šæ–¹æ³•

### 1. ç‰¹å¾çº§è´¡çŒ®åˆ†æ

**æ–¹æ³•**: çº¿æ€§æƒé‡åˆ†è§£

**åŸç†**:
```python
# TurnoverHeadçš„ç¬¬ä¸€å±‚æ˜¯Linear
logit = W Â· concat([employee_emb, job_emb]) + b

# æ¯ä¸ªç‰¹å¾çš„è´¡çŒ®
contribution_i = W_i * x_i
```

**è¾“å‡º**:
- Topæ­£å‘ç‰¹å¾ (å¢åŠ ç¦»èŒé£é™©)
- Topè´Ÿå‘ç‰¹å¾ (é™ä½ç¦»èŒé£é™©)
- Biasè´¡çŒ®

**ç¤ºä¾‹**:
```json
{
  "employee_id": 0,
  "turnover_probability": 0.19,
  "prediction": "Low Risk",
  "top_positive_features": [
    {"name": "skill_freq_15", "contribution": 0.056},
    {"name": "skill_freq_4", "contribution": 0.053}
  ],
  "top_negative_features": [
    {"name": "skill_prof_1", "contribution": -0.085},
    {"name": "feature_248", "contribution": -0.077}
  ]
}
```

**è§£è¯»**:
- è´Ÿå‘è´¡çŒ®å ä¼˜ â†’ é¢„æµ‹ä¸ºä½é£é™©
- `skill_prof_1` (-0.085) æ˜¯æœ€å¼ºä¿æŠ¤å› ç´ 

---

### 2. å›¾ç»“æ„è´¡çŒ®åˆ†æ

**æ–¹æ³•**: é‚»å±…é‡è¦æ€§åˆ†æ

**åŸç†**:
```python
# ä½¿ç”¨embeddingç›¸ä¼¼åº¦ä½œä¸ºé‡è¦æ€§ä»£ç†
importance = cosine_similarity(employee_emb, neighbor_emb)
```

**è¾“å‡º**:
- å½“å‰å²—ä½çš„é‡è¦æ€§åˆ†æ•°
- å…³é”®å…¬å¸å…³ç³»
- åå¥½å²—ä½ç±»å‹

**ç¤ºä¾‹**:
```json
{
  "employee_id": 0,
  "important_relations": [
    {
      "relation_type": "assigned_to_current_job",
      "target_id": 42,
      "importance_score": 0.73
    }
  ]
}
```

**è§£è¯»**:
- é‡è¦æ€§åˆ†æ•°0.73è¡¨ç¤ºå½“å‰å²—ä½ä¸å‘˜å·¥åŒ¹é…åº¦è¾ƒé«˜
- é«˜åŒ¹é…åº¦ â†’ é™ä½ç¦»èŒé£é™©

---

### 3. åå¥½è§£é‡Š

**æ–¹æ³•**: Pairwiseåˆ†æ•°å¯¹æ¯”

**åŸç†**:
```python
# Dual-Headæ¨¡å‹ä½¿ç”¨dot product
score_A = employee_emb Â· post_A_emb
score_B = employee_emb Â· post_B_emb

margin = score_A - score_B  # åå¥½å¼ºåº¦
```

**è¾“å‡º**:
- åå¥½å²—ä½vséåå¥½å²—ä½
- åˆ†æ•°å·®è·(margin)
- å¯¹é½ç»´åº¦åˆ†æ

**ç¤ºä¾‹**:
```json
{
  "employee_id": 15,
  "preferred_post": 23,
  "dispreferred_post": 67,
  "preference_score": 0.82,
  "dispreference_score": 0.31,
  "margin": 0.51,
  "confidence": "High"
}
```

**è§£è¯»**:
- Margin 0.51 > 0.5 â†’ é«˜ç½®ä¿¡åº¦åå¥½
- å‘˜å·¥ä¸å²—ä½23çš„embeddingé«˜åº¦å¯¹é½

---

## ä½¿ç”¨æŒ‡å—

### å¿«é€Ÿå¼€å§‹

**æ­¥éª¤1: è®­ç»ƒæ¨¡å‹** (å¦‚å·²è®­ç»ƒå¯è·³è¿‡)
```bash
python scripts/train_dual_head.py
```

**æ­¥éª¤2: ç”Ÿæˆè§£é‡Š**
```bash
python scripts/explain_predictions.py \
    --run-dir outputs/dual_head/dual_head_main \
    --explain-ids 0 5 10 15 20 \
    --visualize
```

**æ­¥éª¤3: æŸ¥çœ‹ç»“æœ**
```bash
ls outputs/dual_head/dual_head_main/explanations/
```

### è¾“å‡ºæ–‡ä»¶è¯´æ˜

| æ–‡ä»¶ | å†…å®¹ | ç”¨é€” |
|------|------|------|
| `employee_XXXX_features.json` | ç‰¹å¾è´¡çŒ®è¯¦æƒ… | äº†è§£ç¦»èŒé£é™©æ¥æº |
| `employee_XXXX_neighbors.json` | é‚»å±…é‡è¦æ€§ | å›¾ç»“æ„å½±å“åˆ†æ |
| `employee_XXXX_importance.png` | ç‰¹å¾å¯è§†åŒ– | ç›´è§‚å±•ç¤º |
| `employee_XXXX_subgraph.png` | å…³ç³»å­å›¾ | å›¾ç»“æ„å¯è§†åŒ– |
| `preference_explanations.json` | åå¥½è§£é‡Š | ç†è§£æ¨èç†ç”± |
| `preference_comparison_X.png` | åå¥½å¯¹æ¯”å›¾ | å¯è§†åŒ–åå¥½ |
| `summary.json` | æ€»ç»“æŠ¥å‘Š | é«˜å±‚æ¬¡æ¦‚è§ˆ |

---

## ç¤ºä¾‹åˆ†æ

### æ¡ˆä¾‹1: ä½é£é™©å‘˜å·¥ (Employee 0)

**é¢„æµ‹**: Low Risk (p=0.19)

**å…³é”®å‘ç°**:

**Topä¿æŠ¤å› ç´ ** (é™ä½ç¦»èŒé£é™©):
```
1. skill_prof_1:    -0.085  (é«˜æŠ€èƒ½ç†Ÿç»ƒåº¦)
2. feature_248:     -0.077  (æœªçŸ¥ç‰¹å¾)
3. feature_220:     -0.053
```

**Topé£é™©å› ç´ ** (å¢åŠ ç¦»èŒé£é™©):
```
1. feature_153:     +0.064
2. skill_freq_15:   +0.056  (æŠ€èƒ½ä½¿ç”¨é¢‘ç‡)
3. skill_freq_4:    +0.053
```

**å›¾ç»“æ„è´¡çŒ®**:
```
- å½“å‰å²—ä½åŒ¹é…åº¦: 0.73 (é«˜)
â†’ å²—ä½æ»¡æ„åº¦é«˜,é™ä½ç¦»èŒé£é™©
```

**ä¸šåŠ¡è§£è¯»**:
- âœ… è¯¥å‘˜å·¥æŠ€èƒ½ç†Ÿç»ƒåº¦é«˜ (`skill_prof_1`)
- âœ… å½“å‰å²—ä½åŒ¹é…åº¦å¥½ (0.73)
- âš ï¸ æŸäº›æŠ€èƒ½ä½¿ç”¨é¢‘ç‡å¯èƒ½åé«˜,éœ€è¦å…³æ³¨å·¥ä½œå¼ºåº¦
- **ç»“è®º**: æ•´ä½“ä½é£é™©,ä½†å¯ä¼˜åŒ–å·¥ä½œé‡åˆ†é…

---

### æ¡ˆä¾‹2: åå¥½æ¨èè§£é‡Š (Employee 15)

**åå¥½**: å²—ä½23 > å²—ä½67

**åˆ†æ•°**:
```
å²—ä½23 (åå¥½):      0.82
å²—ä½67 (éåå¥½):    0.31
Margin:             0.51 (é«˜ç½®ä¿¡åº¦)
```

**embeddingå¯¹é½åˆ†æ**:
```
Topå¯¹é½ç»´åº¦: [45, 78, 102, 23, 67]
â†’ è¿™äº›ç»´åº¦ä¸Š,å‘˜å·¥ä¸å²—ä½23é«˜åº¦ç›¸ä¼¼
```

**ä¸šåŠ¡è§£è¯»**:
- âœ… å‘˜å·¥ä¸å²—ä½23çš„æŠ€èƒ½/å…´è¶£é«˜åº¦åŒ¹é…
- âš ï¸ å²—ä½67åŒ¹é…åº¦è¾ƒä½
- **æ¨è**: ä¼˜å…ˆè€ƒè™‘å²—ä½23ç±»å‹çš„æœºä¼š

---

## æŠ€æœ¯ç»†èŠ‚

### å®ç°æ¶æ„

```python
# æ ¸å¿ƒæ¨¡å—
src/models/
â”œâ”€â”€ explanations.py          # æ ¸å¿ƒè§£é‡Šé€»è¾‘
â”‚   â”œâ”€â”€ FeatureContributionAnalyzer
â”‚   â”œâ”€â”€ AttentionWeightExtractor
â”‚   â””â”€â”€ PreferenceExplainer
â”‚
â”œâ”€â”€ visualization.py         # å¯è§†åŒ–å·¥å…·
â”‚   â”œâ”€â”€ plot_explanation_subgraph()
â”‚   â””â”€â”€ plot_preference_comparison()
â”‚
â””â”€â”€ scripts/
    â””â”€â”€ explain_predictions.py  # å‘½ä»¤è¡Œæ¥å£
```

### å…³é”®å‡½æ•°

**1. ç‰¹å¾è´¡çŒ®è®¡ç®—**
```python
def compute_contributions(
    employee_embeddings: torch.Tensor,
    job_embeddings: torch.Tensor,
    employee_ids: List[int],
) -> List[Dict]:
    # è·å–çº¿æ€§å±‚æƒé‡
    weights = turnover_head.net[0].weight

    # è®¡ç®—è´¡çŒ®: w * x
    contributions = weights * concat_embedding

    # æ’åºå¹¶è¿”å›top-k
    return top_k_features
```

**2. é‚»å±…é‡è¦æ€§**
```python
def analyze_neighbor_importance(
    data: HeteroData,
    embeddings: Dict[str, Tensor],
    employee_ids: List[int],
) -> List[Dict]:
    # è®¡ç®—cosineç›¸ä¼¼åº¦
    similarity = cosine_similarity(
        employee_emb,
        neighbor_emb
    )

    return neighbor_importance
```

**3. åå¥½è§£é‡Š**
```python
def explain_pairwise_preference(
    employee_embeddings: Tensor,
    post_embeddings: Tensor,
    triples: Tensor,
) -> List[Dict]:
    # è®¡ç®—pairwiseåˆ†æ•°
    pref_score = employee_emb Â· post_pref_emb
    disp_score = employee_emb Â· post_disp_emb
    margin = pref_score - disp_score

    return explanations
```

---

## å¯è§†åŒ–ç¤ºä¾‹

### 1. ç‰¹å¾é‡è¦æ€§å›¾

![Feature Importance](examples/employee_0000_importance.png)

**è¯´æ˜**:
- ç»¿è‰²æ¡: å¢åŠ ç¦»èŒé£é™©çš„ç‰¹å¾
- çº¢è‰²æ¡: é™ä½ç¦»èŒé£é™©çš„ç‰¹å¾
- é•¿åº¦: è´¡çŒ®å¤§å°

### 2. å…³ç³»å­å›¾

![Subgraph](examples/employee_0000_subgraph.png)

**è¯´æ˜**:
- çº¢è‰²èŠ‚ç‚¹: é«˜é£é™©å‘˜å·¥
- ç»¿è‰²èŠ‚ç‚¹: ä½é£é™©å‘˜å·¥
- è“è‰²èŠ‚ç‚¹: å½“å‰å²—ä½
- è¾¹å®½åº¦: å…³ç³»é‡è¦æ€§

### 3. åå¥½å¯¹æ¯”å›¾

![Preference](examples/preference_comparison_0.png)

**è¯´æ˜**:
- ç»¿è‰²æŸ±: åå¥½å²—ä½åˆ†æ•°
- çº¢è‰²æŸ±: éåå¥½å²—ä½åˆ†æ•°
- Margin: åˆ†æ•°å·®è·

---

## æœªæ¥æ‰©å±• (TODO)

### 1. å…¨å±€è§£é‡Šæ–¹æ³•

**SHAP (SHapley Additive exPlanations)**
```python
# TODO: é›†æˆSHAPåº“
import shap

explainer = shap.DeepExplainer(model, background_data)
shap_values = explainer.shap_values(employee_features)
```

**ä¼˜åŠ¿**:
- ç†è®ºä¿è¯ (Shapleyå€¼)
- å…¨å±€ä¸€è‡´æ€§
- ç‰¹å¾äº¤äº’åˆ†æ

---

### 2. Permutation Importance

**æ–¹æ³•**: æ‰“ä¹±ç‰¹å¾è§‚å¯Ÿæ€§èƒ½ä¸‹é™
```python
# TODO
def permutation_importance(model, data, feature_idx):
    baseline_score = evaluate(model, data)

    # Permute feature
    data_permuted = permute_feature(data, feature_idx)
    permuted_score = evaluate(model, data_permuted)

    importance = baseline_score - permuted_score
    return importance
```

---

### 3. æ³¨æ„åŠ›å¯è§†åŒ–

**è¦æ±‚**: ä¿®æ”¹HGTConvä¿å­˜attentionæƒé‡
```python
# TODO: ä¿®æ”¹src/models/hetero_gnn.py
class HGTConv(nn.Module):
    def forward(self, x_dict, edge_index_dict):
        # ... existing code ...

        # Save attention weights
        self.last_attention = attention_weights

        return h_dict
```

**å¯è§†åŒ–**:
```python
# æå–å¹¶å¯è§†åŒ–attention
attention = model.gnn_layers[-1].last_attention
plot_attention_heatmap(attention)
```

---

### 4. Integrated Gradients

**æ–¹æ³•**: åŸºäºæ¢¯åº¦çš„å½’å› 
```python
# TODO: ä½¿ç”¨Captumåº“
from captum.attr import IntegratedGradients

ig = IntegratedGradients(model)
attributions = ig.attribute(
    inputs=employee_embedding,
    target=turnover_prediction
)
```

---

### 5. GraphMask

**æ–¹æ³•**: å­¦ä¹ é‡è¦å­å›¾
```python
# TODO: å®ç°GraphMask
class GraphMask(nn.Module):
    def forward(self, graph):
        # Learn binary mask for edges/nodes
        mask = learn_mask(graph)

        # Prune graph
        important_subgraph = apply_mask(graph, mask)

        return important_subgraph
```

---

## ä¸Baselineå¯¹æ¯”

### MLP/XGBoostçš„è§£é‡Š

**ç‰¹å¾é‡è¦æ€§**:
```python
# XGBoost
feature_importance = model.feature_importances_

# MLP (éœ€è¦é¢å¤–å·¥å…·)
# 1. Permutation Importance
# 2. LIME
# 3. SHAP
```

**é™åˆ¶**:
- âŒ æ— æ³•åˆ©ç”¨å›¾ç»“æ„ä¿¡æ¯
- âŒ æ— æ³•è§£é‡Šå…³ç³»é‡è¦æ€§
- âŒ æ— æ³•æ•æ‰higher-order patterns

### GNNçš„é¢å¤–æ´å¯Ÿ

**ä¼˜åŠ¿**:
- âœ… **å›¾ç»“æ„è´¡çŒ®**: å“ªäº›å²—ä½/å…¬å¸å…³ç³»é‡è¦
- âœ… **é‚»å±…å½±å“**: åŒäº‹/å›¢é˜Ÿå¯¹ç¦»èŒçš„å½±å“
- âœ… **å¤šè·³ä¼ æ’­**: é—´æ¥å…³ç³»çš„ä½œç”¨
- âœ… **åå¥½è§£é‡Š**: embeddingç©ºé—´çš„è¯­ä¹‰è§£é‡Š

---

## APIå‚è€ƒ

### å‘½ä»¤è¡Œæ¥å£

```bash
python scripts/explain_predictions.py \
    --run-dir <path>              # æ¨¡å‹ç›®å½•
    --explain-ids <id1> <id2>     # å‘˜å·¥IDåˆ—è¡¨
    --output-dir <path>           # è¾“å‡ºç›®å½•(å¯é€‰)
    --top-k <n>                   # Topç‰¹å¾æ•°(é»˜è®¤10)
    --visualize                   # ç”Ÿæˆå¯è§†åŒ–
```

### Python API

```python
from src.models.explanations import (
    FeatureContributionAnalyzer,
    AttentionWeightExtractor,
    PreferenceExplainer,
    generate_explanation_report,
)

# ç”Ÿæˆå®Œæ•´æŠ¥å‘Š
generate_explanation_report(
    model=trained_model,
    turnover_head=turnover_head,
    preference_head=preference_head,
    data=graph_data,
    employee_ids=[0, 5, 10],
    triples=preference_triples,
    scaler_path="data/processed/feature_scaler.pkl",
    feature_names_path="data/processed/feature_names.txt",
    save_dir="outputs/explanations",
)
```

---

## å¸¸è§é—®é¢˜

### Q1: è§£é‡Šæ˜¯å¦å¯é ?

**A**: æˆ‘ä»¬çš„è§£é‡ŠåŸºäº:
1. **çº¿æ€§è¿‘ä¼¼**: TurnoverHeadç¬¬ä¸€å±‚çš„çº¿æ€§æƒé‡
2. **embeddingç›¸ä¼¼åº¦**: ä½œä¸ºæ³¨æ„åŠ›çš„ä»£ç†
3. **Dot productåˆ†è§£**: Preferenceå¤´çš„ç›´æ¥è®¡ç®—

è¿™äº›æ–¹æ³•åœ¨å®è·µä¸­è¢«å¹¿æ³›éªŒè¯,ä½†ä»æ˜¯**è¿‘ä¼¼è§£é‡Š**,ä¸æ˜¯ç²¾ç¡®å› æœå…³ç³»ã€‚

### Q2: å¦‚ä½•å¤„ç†é«˜ç»´embedding?

**A**:
- æˆ‘ä»¬å…³æ³¨**top-kç‰¹å¾** (é»˜è®¤10)
- ä½¿ç”¨**ç»å¯¹è´¡çŒ®å€¼**æ’åº
- æä¾›**å¯è§†åŒ–**è¾…åŠ©ç†è§£

### Q3: è´Ÿå‘è´¡çŒ®æ„å‘³ç€ä»€ä¹ˆ?

**A**:
- **æ­£å‘è´¡çŒ®**: å¢åŠ ç¦»èŒé£é™©
- **è´Ÿå‘è´¡çŒ®**: é™ä½ç¦»èŒé£é™©(ä¿æŠ¤å› ç´ )
- **Bias**: æ¨¡å‹çš„åŸºçº¿å€¾å‘

### Q4: å¦‚ä½•éªŒè¯è§£é‡Šçš„æ­£ç¡®æ€§?

**A**:
1. **ä¸šåŠ¡éªŒè¯**: ä¸HRä¸“å®¶è®¨è®º
2. **å¯¹æ¯”å®éªŒ**: ä¿®æ”¹å…³é”®ç‰¹å¾è§‚å¯Ÿé¢„æµ‹å˜åŒ–
3. **A/Bæµ‹è¯•**: åœ¨çœŸå®åœºæ™¯ä¸­æµ‹è¯•

---

## å‚è€ƒæ–‡çŒ®

1. **GNN Explainability**:
   - GNNExplainer (Ying et al., NeurIPS 2019)
   - GraphMask (Schlichtkrull et al., ICML 2021)

2. **General XAI**:
   - SHAP (Lundberg & Lee, NIPS 2017)
   - LIME (Ribeiro et al., KDD 2016)
   - Integrated Gradients (Sundararajan et al., ICML 2017)

3. **Attention Visualization**:
   - Attention Is All You Need (Vaswani et al., 2017)
   - Analyzing and Interpreting Neural Networks for NLP (Belinkov & Glass, 2019)

---

## æ€»ç»“

æˆ‘ä»¬å®ç°äº†ä¸€å¥—**å®Œæ•´çš„GNNå¯è§£é‡Šæ€§æ¡†æ¶**:

âœ… **ç‰¹å¾çº§**: çº¿æ€§æƒé‡åˆ†è§£
âœ… **å›¾ç»“æ„çº§**: é‚»å±…é‡è¦æ€§åˆ†æ
âœ… **åå¥½çº§**: Pairwiseå¯¹æ¯”è§£é‡Š
âœ… **å¯è§†åŒ–**: è‡ªåŠ¨ç”Ÿæˆå›¾è¡¨
âœ… **æ˜“ç”¨æ€§**: ç®€å•å‘½ä»¤è¡Œæ¥å£

**ä¸‹ä¸€æ­¥**:
1. å®æ–½TODOä¸­çš„é«˜çº§æ–¹æ³• (SHAP, Attentionç­‰)
2. ä¸ä¸šåŠ¡å›¢é˜Ÿåˆä½œéªŒè¯è§£é‡Š
3. æ„å»ºäº¤äº’å¼dashboard

---

*æ–‡æ¡£ç‰ˆæœ¬: 1.0*
*æœ€åæ›´æ–°: 2025-10-19*
*ç»´æŠ¤è€…: GNN Explainability Team*
