"""
ç‰¹å¾æå–æ¨¡å—
"""
import pandas as pd
import numpy as np
from sklearn.preprocessing import StandardScaler
from typing import Dict, List, Tuple
import pickle
from pathlib import Path


class FeatureExtractor:
    """å‘˜å·¥ç‰¹å¾æå–å™¨"""
    
    def __init__(self):
        self.scaler = StandardScaler()
        self.feature_names = []
        
    def extract_basic_features(self, df: pd.DataFrame) -> Tuple[np.ndarray, List[str]]:
        """
        æå–åŸºç¡€å±æ€§ç‰¹å¾ (7ç»´)
        
        Args:
            df: åŸå§‹æ•°æ®æ¡†
            
        Returns:
            features: (n_samples, 7)
            feature_names: ç‰¹å¾åç§°åˆ—è¡¨
        """
        print("ğŸ“Š æå–åŸºç¡€ç‰¹å¾...")
        
        features = []
        feature_names = []
        
        # Q6: æ€»å·¥é¾„ (æ•°å€¼å‹)
        q6 = pd.to_numeric(df['Q6'], errors='coerce').fillna(0).values
        features.append(q6)
        feature_names.append('tenure_total')
        
        # Q7: åœ¨å²—å¹´é™ (æ•°å€¼å‹)
        q7 = pd.to_numeric(df['Q7'], errors='coerce').fillna(0).values
        features.append(q7)
        feature_names.append('tenure_current')
        
        # Q8: æœ€è¿‘æ¢å·¥ä½œæ—¶é—´ (åºæ•°å‹)
        q8_mapping = {
            'ä»æœª': 0, '<1å¹´': 1, '1å¹´': 2, '2å¹´': 3, 
            '3å¹´': 4, '4å¹´': 5, '5å¹´+': 6
        }
        q8 = df['Q8'].map(q8_mapping).fillna(0).values
        features.append(q8)
        feature_names.append('last_job_change')
        
        # Q9: åŸ¹è®­æ—¶é•¿ (æ•°å€¼å‹)
        q9 = pd.to_numeric(df['Q9'], errors='coerce').fillna(0).values
        features.append(q9)
        feature_names.append('training_hours')
        
        # Q10: é€šå‹¤æ—¶é—´ (æ•°å€¼å‹)
        q10 = pd.to_numeric(df['Q10'], errors='coerce').fillna(0).values
        features.append(q10)
        feature_names.append('commute_minutes')
        
        # Q11: åŸå¸‚æ»¡æ„åº¦ (1-10åˆ†)
        q11 = pd.to_numeric(df['Q11'], errors='coerce').fillna(5).values
        features.append(q11)
        feature_names.append('city_satisfaction')
        
        # Q15: æœˆè–ªåŒºé—´ (åºæ•°å‹)
        q15_mapping = {
            '<5k': 0, '5?8k': 1, '8?12k': 2, 
            '12?20k': 3, '20?35k': 4, '35k+': 5
        }
        q15 = df['Q15'].map(q15_mapping).fillna(1).values
        features.append(q15)
        feature_names.append('salary_band')
        
        result = np.column_stack(features)
        print(f"  âœ… åŸºç¡€ç‰¹å¾: {result.shape}")
        
        return result, feature_names
    
    def extract_fit_features(self, df: pd.DataFrame) -> Tuple[np.ndarray, List[str]]:
        """
        æå–äººå²—åŒ¹é…åº¦ç‰¹å¾ (5ç»´)
        Q12ç³»åˆ—: Likert 7åˆ†åˆ¶
        
        Args:
            df: åŸå§‹æ•°æ®æ¡†
            
        Returns:
            features: (n_samples, 5)
            feature_names: ç‰¹å¾åç§°åˆ—è¡¨
        """
        print("ğŸ“Š æå–äººå²—åŒ¹é…åº¦ç‰¹å¾...")
        
        likert_mapping = {
            'éå¸¸ä¸åŒæ„': 1, 'ä¸åŒæ„': 2, 'ç•¥ä¸åŒæ„': 3, 'ä¸€èˆ¬': 4,
            'ç•¥åŒæ„': 5, 'åŒæ„': 6, 'éå¸¸åŒæ„': 7
        }
        
        features = []
        feature_names = []
        
        for i in range(1, 6):
            col = f'Q12_{i}'
            values = df[col].map(likert_mapping).fillna(4).values
            features.append(values)
            feature_names.append(f'fit_{i}')
        
        result = np.column_stack(features)
        print(f"  âœ… äººå²—åŒ¹é…ç‰¹å¾: {result.shape}")
        
        return result, feature_names
    
    def extract_skill_features(self, df: pd.DataFrame) -> Tuple[np.ndarray, List[str]]:
        """
        æå–æŠ€èƒ½ç‰¹å¾ (30ç»´: 15é¢‘ç‡ + 15ç†Ÿç»ƒåº¦)
        Q13ç³»åˆ—: ä½¿ç”¨é¢‘ç‡ (1-5)
        Q14ç³»åˆ—: ç†Ÿç»ƒåº¦ (1-5)
        
        Args:
            df: åŸå§‹æ•°æ®æ¡†
            
        Returns:
            features: (n_samples, 30)
            feature_names: ç‰¹å¾åç§°åˆ—è¡¨
        """
        print("ğŸ“Š æå–æŠ€èƒ½ç‰¹å¾...")
        
        # é¢‘ç‡æ˜ å°„
        freq_mapping = {
            'å‡ ä¹ä¸ç”¨': 1, 'å¶å°”ä½¿ç”¨': 2, 'ä¸€èˆ¬': 3, 
            'è¾ƒé¢‘ç¹': 4, 'æ¯å¤©é«˜å¼ºåº¦': 5
        }
        
        # ç†Ÿç»ƒåº¦æ˜ å°„
        prof_mapping = {
            'åˆå­¦': 1, 'å…¥é—¨': 2, 'ç†Ÿç»ƒ': 3, 'ç²¾é€š': 4, 'ä¸“å®¶': 5
        }
        
        features = []
        feature_names = []
        
        # Q13: ä½¿ç”¨é¢‘ç‡
        for i in range(1, 16):
            col = f'Q13_{i}'
            values = df[col].map(freq_mapping).fillna(3).values
            features.append(values)
            feature_names.append(f'skill_freq_{i}')
        
        # Q14: ç†Ÿç»ƒåº¦
        for i in range(1, 16):
            col = f'Q14_{i}'
            values = df[col].map(prof_mapping).fillna(3).values
            features.append(values)
            feature_names.append(f'skill_prof_{i}')
        
        result = np.column_stack(features)
        print(f"  âœ… æŠ€èƒ½ç‰¹å¾: {result.shape}")
        
        return result, feature_names
    
    def extract_economic_features(self, df: pd.DataFrame) -> Tuple[np.ndarray, List[str]]:
        """
        æå–ç»æµæŸå¤±æ„ŸçŸ¥ç‰¹å¾ (5ç»´)
        Q16ç³»åˆ—: Likert 7åˆ†åˆ¶
        
        Args:
            df: åŸå§‹æ•°æ®æ¡†
            
        Returns:
            features: (n_samples, 5)
            feature_names: ç‰¹å¾åç§°åˆ—è¡¨
        """
        print("ğŸ“Š æå–ç»æµæŸå¤±ç‰¹å¾...")
        
        likert_mapping = {
            'éå¸¸ä¸åŒæ„': 1, 'ä¸åŒæ„': 2, 'ç•¥ä¸åŒæ„': 3, 'ä¸€èˆ¬': 4,
            'ç•¥åŒæ„': 5, 'åŒæ„': 6, 'éå¸¸åŒæ„': 7
        }
        
        features = []
        feature_names = []
        
        for i in range(1, 6):
            col = f'Q16_{i}'
            values = df[col].map(likert_mapping).fillna(4).values
            features.append(values)
            feature_names.append(f'economic_{i}')
        
        result = np.column_stack(features)
        print(f"  âœ… ç»æµæŸå¤±ç‰¹å¾: {result.shape}")
        
        return result, feature_names
    
    def extract_all_features(self, df: pd.DataFrame, fit=True) -> Tuple[np.ndarray, List[str]]:
        """
        æå–æ‰€æœ‰ç‰¹å¾
        
        Args:
            df: åŸå§‹æ•°æ®æ¡†
            fit: æ˜¯å¦æ‹Ÿåˆæ ‡å‡†åŒ–å™¨
            
        Returns:
            features: (n_samples, 47) ç‰¹å¾çŸ©é˜µ
            feature_names: ç‰¹å¾åç§°åˆ—è¡¨
        """
        print("\n" + "="*60)
        print("ç‰¹å¾æå–ç®¡é“")
        print("="*60)
        
        # æå–å„ç»„ç‰¹å¾
        basic_feats, basic_names = self.extract_basic_features(df)
        fit_feats, fit_names = self.extract_fit_features(df)
        skill_feats, skill_names = self.extract_skill_features(df)
        econ_feats, econ_names = self.extract_economic_features(df)
        
        # åˆå¹¶ç‰¹å¾
        all_features = np.column_stack([
            basic_feats, fit_feats, skill_feats, econ_feats
        ])
        
        all_names = basic_names + fit_names + skill_names + econ_names
        
        print(f"\nğŸ“Š ç‰¹å¾åˆå¹¶å®Œæˆ: {all_features.shape}")
        print(f"   - åŸºç¡€ç‰¹å¾: {len(basic_names)}ç»´")
        print(f"   - äººå²—åŒ¹é…: {len(fit_names)}ç»´")
        print(f"   - æŠ€èƒ½ç‰¹å¾: {len(skill_names)}ç»´")
        print(f"   - ç»æµæŸå¤±: {len(econ_names)}ç»´")
        print(f"   - æ€»è®¡: {len(all_names)}ç»´")
        
        # æ ‡å‡†åŒ–
        if fit:
            print("\nğŸ”§ æ‹Ÿåˆæ ‡å‡†åŒ–å™¨...")
            features_scaled = self.scaler.fit_transform(all_features)
        else:
            print("\nğŸ”§ åº”ç”¨æ ‡å‡†åŒ–å™¨...")
            features_scaled = self.scaler.transform(all_features)
        
        self.feature_names = all_names
        
        print(f"âœ… ç‰¹å¾æå–å®Œæˆï¼")
        print(f"   - ç‰¹å¾å½¢çŠ¶: {features_scaled.shape}")
        print(f"   - ç‰¹å¾å‡å€¼: {features_scaled.mean():.4f}")
        print(f"   - ç‰¹å¾æ ‡å‡†å·®: {features_scaled.std():.4f}")
        
        return features_scaled, all_names
    
    def save(self, path: str):
        """ä¿å­˜ç‰¹å¾æå–å™¨"""
        Path(path).parent.mkdir(parents=True, exist_ok=True)
        
        with open(path, 'wb') as f:
            pickle.dump({
                'scaler': self.scaler,
                'feature_names': self.feature_names
            }, f)
        
        print(f"âœ… ç‰¹å¾æå–å™¨å·²ä¿å­˜: {path}")
    
    def load(self, path: str):
        """åŠ è½½ç‰¹å¾æå–å™¨"""
        with open(path, 'rb') as f:
            data = pickle.load(f)
            self.scaler = data['scaler']
            self.feature_names = data['feature_names']
        
        print(f"âœ… ç‰¹å¾æå–å™¨å·²åŠ è½½: {path}")


def main():
    """æ¼”ç¤ºç‰¹å¾æå–"""
    import sys
    sys.path.append('/Users/yu/code/code2510/gnn')
    from src.data_processing.load_data import DataLoader
    
    # åŠ è½½æ•°æ®
    loader = DataLoader('/Users/yu/code/code2510/gnn/data/raw/originaldata.csv')
    df = loader.load()
    
    # æå–ç‰¹å¾
    extractor = FeatureExtractor()
    features, feature_names = extractor.extract_all_features(df, fit=True)
    
    # ä¿å­˜ç‰¹å¾
    Path('/Users/yu/code/code2510/gnn/data/processed').mkdir(parents=True, exist_ok=True)
    np.save('/Users/yu/code/code2510/gnn/data/processed/employee_features.npy', features)
    with open('/Users/yu/code/code2510/gnn/data/processed/feature_names.txt', 'w') as f:
        f.write('\n'.join(feature_names))
    
    # ä¿å­˜æå–å™¨
    Path('/Users/yu/code/code2510/gnn/models').mkdir(parents=True, exist_ok=True)
    extractor.save('/Users/yu/code/code2510/gnn/models/feature_extractor.pkl')
    
    print("\nâœ… ç‰¹å¾å·²ä¿å­˜åˆ° data/processed/")


if __name__ == '__main__':
    main()