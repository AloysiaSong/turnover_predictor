"""
åŒæ„å›¾æ„å»ºå™¨
å°†å¼‚æ„å›¾è½¬æ¢ä¸ºåŒæ„å›¾ï¼ˆæ‰€æœ‰èŠ‚ç‚¹è§†ä¸ºåŒä¸€ç±»å‹ï¼‰

æ ¸å¿ƒæ€è·¯:
1. åªä½¿ç”¨å‘˜å·¥èŠ‚ç‚¹ï¼ˆ500ä¸ªï¼‰
2. åŸºäºå‘˜å·¥ä¹‹é—´çš„ç›¸ä¼¼æ€§æ„å»ºè¾¹
3. å¤šç§è¾¹æ„å»ºç­–ç•¥ï¼šå…±åŒå±æ€§ã€æŠ€èƒ½ç›¸ä¼¼åº¦ã€k-NN
4. ç¡®ä¿å›¾è¿é€šæ€§
"""

import torch
import numpy as np
import pandas as pd
from torch_geometric.data import Data
from pathlib import Path
from sklearn.metrics.pairwise import cosine_similarity
from sklearn.neighbors import kneighbors_graph
import json


class HomogeneousGraphBuilder:
    """åŒæ„å›¾æ„å»ºå™¨"""
    
    def __init__(self, data_dir='data'):
        """
        Args:
            data_dir: æ•°æ®ç›®å½•è·¯å¾„
        """
        self.data_dir = Path(data_dir)
        self.raw_dir = self.data_dir / 'raw'
        self.processed_dir = self.data_dir / 'processed'
        self.edges_dir = self.data_dir / 'edges'
        self.splits_dir = self.data_dir / 'splits'
        
        # ç»Ÿè®¡ä¿¡æ¯
        self.stats = {}
        
    def build(self, strategy='hybrid', k=10, similarity_threshold=0.5):
        """
        æ„å»ºåŒæ„å›¾
        
        Args:
            strategy: è¾¹æ„å»ºç­–ç•¥
                - 'attribute': åŸºäºå…±åŒå±æ€§
                - 'similarity': åŸºäºç‰¹å¾ç›¸ä¼¼åº¦
                - 'knn': åŸºäºkè¿‘é‚»
                - 'hybrid': æ··åˆç­–ç•¥ï¼ˆæ¨èï¼‰
            k: k-NNä¸­çš„kå€¼
            similarity_threshold: ç›¸ä¼¼åº¦é˜ˆå€¼
            
        Returns:
            data: PyG Dataå¯¹è±¡
        """
        print("\n" + "="*70)
        print("ğŸ”¨ åŒæ„å›¾æ„å»ºå™¨")
        print("="*70)
        
        # 1. åŠ è½½æ•°æ®
        print("\nğŸ“‚ Step 1/6: åŠ è½½æ•°æ®...")
        X, y, df = self._load_data()
        
        # 2. æ„å»ºè¾¹
        print(f"\nğŸ”— Step 2/6: æ„å»ºè¾¹ (ç­–ç•¥={strategy})...")
        edge_index, edge_weights = self._build_edges(df, X, strategy, k, similarity_threshold)
        
        # 3. åŠ è½½åˆ’åˆ†mask
        print("\nğŸ“Š Step 3/6: åŠ è½½æ•°æ®åˆ’åˆ†...")
        train_mask, val_mask, test_mask = self._load_masks()
        
        # 4. åˆ›å»ºPyG Dataå¯¹è±¡
        print("\nğŸ—ï¸ Step 4/6: åˆ›å»ºPyG Dataå¯¹è±¡...")
        data = self._create_pyg_data(X, y, edge_index, edge_weights, 
                                     train_mask, val_mask, test_mask)
        
        # 5. éªŒè¯å›¾ç»“æ„
        print("\nâœ… Step 5/6: éªŒè¯å›¾ç»“æ„...")
        self._validate_graph(data)
        
        # 6. ä¿å­˜
        print("\nğŸ’¾ Step 6/6: ä¿å­˜åŒæ„å›¾...")
        save_path = self.processed_dir / 'homo_graph.pt'
        torch.save(data, save_path)
        
        # ä¿å­˜ç»Ÿè®¡ä¿¡æ¯
        self._save_statistics(strategy, k, similarity_threshold)
        
        print("\n" + "="*70)
        print(f"âœ… åŒæ„å›¾æ„å»ºå®Œæˆï¼")
        print(f"ğŸ“ å·²ä¿å­˜: {save_path}")
        print("="*70)
        
        return data
    
    def _load_data(self):
        """åŠ è½½ç‰¹å¾ã€æ ‡ç­¾å’ŒåŸå§‹æ•°æ®"""
        # ç‰¹å¾å’Œæ ‡ç­¾
        X = np.load(self.processed_dir / 'employee_features.npy')
        y = np.load(self.processed_dir / 'y_turnover_binary.npy')
        
        # åŸå§‹æ•°æ®ï¼ˆç”¨äºæ„å»ºå±æ€§è¾¹ï¼‰
        df = pd.read_csv(
            self.raw_dir / 'originaldata.csv',
            encoding='gbk',
            skiprows=1
        )
        
        print(f"   âœ“ å‘˜å·¥èŠ‚ç‚¹æ•°: {len(X)}")
        print(f"   âœ“ ç‰¹å¾ç»´åº¦: {X.shape[1]}")
        print(f"   âœ“ ç¦»èŒå‘˜å·¥: {y.sum()} ({y.mean():.2%})")
        print(f"   âœ“ åœ¨èŒå‘˜å·¥: {(1-y).sum()} ({(1-y).mean():.2%})")
        
        self.stats['num_nodes'] = len(X)
        self.stats['num_features'] = X.shape[1]
        self.stats['turnover_rate'] = float(y.mean())
        
        return X, y, df
    
    def _load_masks(self):
        """åŠ è½½è®­ç»ƒ/éªŒè¯/æµ‹è¯•mask"""
        # å°è¯•åŠ è½½.npyæ–‡ä»¶
        train_mask_path = self.splits_dir / 'train_mask.npy'
        
        if train_mask_path.exists():
            # å¦‚æœå­˜åœ¨.npyæ–‡ä»¶ï¼Œç›´æ¥åŠ è½½
            train_mask = np.load(train_mask_path)
            val_mask = np.load(self.splits_dir / 'val_mask.npy')
            test_mask = np.load(self.splits_dir / 'test_mask.npy')
        else:
            # å¦åˆ™ä».ptæ–‡ä»¶åŠ è½½
            print("   â„¹ï¸ ä».ptæ–‡ä»¶åŠ è½½mask...")
            train_mask = torch.load(self.splits_dir / 'train_mask.pt').numpy()
            val_mask = torch.load(self.splits_dir / 'val_mask.pt').numpy()
            test_mask = torch.load(self.splits_dir / 'test_mask.pt').numpy()
        
        print(f"   âœ“ è®­ç»ƒé›†: {train_mask.sum()} ({train_mask.mean():.1%})")
        print(f"   âœ“ éªŒè¯é›†: {val_mask.sum()} ({val_mask.mean():.1%})")
        print(f"   âœ“ æµ‹è¯•é›†: {test_mask.sum()} ({test_mask.mean():.1%})")
        
        return train_mask, val_mask, test_mask
    
    def _build_edges(self, df, X, strategy, k, similarity_threshold):
        """
        æ„å»ºè¾¹ç´¢å¼•
        
        Returns:
            edge_index: [2, num_edges]
            edge_weights: [num_edges] å¯é€‰çš„è¾¹æƒé‡
        """
        if strategy == 'attribute':
            edge_index, edge_weights = self._build_attribute_edges(df)
        elif strategy == 'similarity':
            edge_index, edge_weights = self._build_similarity_edges(X, similarity_threshold)
        elif strategy == 'knn':
            edge_index, edge_weights = self._build_knn_edges(X, k)
        elif strategy == 'hybrid':
            edge_index, edge_weights = self._build_hybrid_edges(df, X, k, similarity_threshold)
        else:
            raise ValueError(f"Unknown strategy: {strategy}")
        
        num_edges = edge_index.shape[1]
        avg_degree = num_edges / len(df)
        
        print(f"   âœ“ è¾¹æ•°: {num_edges:,}")
        print(f"   âœ“ å¹³å‡åº¦æ•°: {avg_degree:.2f}")
        print(f"   âœ“ è¾¹æƒé‡èŒƒå›´: [{edge_weights.min():.3f}, {edge_weights.max():.3f}]")
        
        self.stats['num_edges'] = num_edges
        self.stats['avg_degree'] = float(avg_degree)
        
        return edge_index, edge_weights
    
    def _build_attribute_edges(self, df):
        """
        ç­–ç•¥1: åŸºäºå…±åŒå±æ€§æ„å»ºè¾¹
        
        è¿æ¥è§„åˆ™:
        - åŒå²—ä½ç±»å‹ â†’ æƒé‡1.0
        - åŒå…¬å¸è§„æ¨¡ â†’ æƒé‡0.7
        - åŒå…¬å¸ç±»å‹ â†’ æƒé‡0.7
        """
        print("   ğŸ“‹ ä½¿ç”¨å±æ€§è¾¹ç­–ç•¥...")
        
        edges = []
        weights = []
        
        # ä¿®å¤ï¼šä½¿ç”¨å®é™…çš„åˆ—å
        post_types = df['Q7'].values
        company_sizes = df['Q8'].values
        company_types = df['Q9'].values
        
        num_nodes = len(df)
        
        for i in range(num_nodes):
            for j in range(i + 1, num_nodes):
                edge_weight = 0.0
                
                # åŒå²—ä½
                if post_types[i] == post_types[j]:
                    edge_weight = 1.0
                # åŒå…¬å¸è§„æ¨¡
                elif company_sizes[i] == company_sizes[j]:
                    edge_weight = 0.7
                # åŒå…¬å¸ç±»å‹
                elif company_types[i] == company_types[j]:
                    edge_weight = 0.7
                
                if edge_weight > 0:
                    # æ— å‘å›¾ï¼šæ·»åŠ åŒå‘è¾¹
                    edges.append([i, j])
                    edges.append([j, i])
                    weights.extend([edge_weight, edge_weight])
        
        if not edges:
            print("   âš ï¸ è­¦å‘Š: æœªæ‰¾åˆ°ä»»ä½•å±æ€§è¾¹ï¼Œæ·»åŠ è‡ªç¯")
            edges = [[i, i] for i in range(num_nodes)]
            weights = [1.0] * num_nodes
        
        edge_index = np.array(edges).T
        edge_weights = np.array(weights)
        
        print(f"   âœ“ åŸºäºå±æ€§çš„è¾¹: {len(edges)}")
        
        return edge_index, edge_weights
    
    def _build_similarity_edges(self, X, threshold):
        """
        ç­–ç•¥2: åŸºäºç‰¹å¾ç›¸ä¼¼åº¦æ„å»ºè¾¹
        
        ä½¿ç”¨ä½™å¼¦ç›¸ä¼¼åº¦ï¼Œè¿æ¥ç›¸ä¼¼åº¦ > threshold çš„èŠ‚ç‚¹å¯¹
        """
        print(f"   ğŸ“ ä½¿ç”¨ç›¸ä¼¼åº¦è¾¹ç­–ç•¥ (é˜ˆå€¼={threshold})...")
        
        # è®¡ç®—ä½™å¼¦ç›¸ä¼¼åº¦çŸ©é˜µ
        similarity = cosine_similarity(X)
        
        # è®¾ç½®å¯¹è§’çº¿ä¸º0ï¼ˆé¿å…è‡ªç¯ï¼‰
        np.fill_diagonal(similarity, 0)
        
        # æ‰¾åˆ°ç›¸ä¼¼åº¦ > threshold çš„è¾¹
        edges = []
        weights = []
        
        num_nodes = X.shape[0]
        for i in range(num_nodes):
            for j in range(i + 1, num_nodes):
                if similarity[i, j] > threshold:
                    edges.append([i, j])
                    edges.append([j, i])
                    weights.extend([similarity[i, j], similarity[i, j]])
        
        if not edges:
            print(f"   âš ï¸ è­¦å‘Š: é˜ˆå€¼{threshold}è¿‡é«˜ï¼Œé™ä½åˆ°{threshold-0.1}")
            return self._build_similarity_edges(X, threshold - 0.1)
        
        edge_index = np.array(edges).T
        edge_weights = np.array(weights)
        
        print(f"   âœ“ åŸºäºç›¸ä¼¼åº¦çš„è¾¹: {len(edges)}")
        print(f"   âœ“ å¹³å‡ç›¸ä¼¼åº¦: {edge_weights.mean():.3f}")
        
        return edge_index, edge_weights
    
    def _build_knn_edges(self, X, k):
        """
        ç­–ç•¥3: åŸºäºkè¿‘é‚»æ„å»ºè¾¹
        
        æ¯ä¸ªèŠ‚ç‚¹è¿æ¥åˆ°å…¶kä¸ªæœ€è¿‘é‚»å±…
        """
        print(f"   ğŸ¯ ä½¿ç”¨k-NNè¾¹ç­–ç•¥ (k={k})...")
        
        # æ„å»ºk-NNå›¾
        A = kneighbors_graph(
            X, 
            n_neighbors=k,
            mode='distance',
            include_self=False
        )
        
        # è½¬æ¢ä¸ºCOOæ ¼å¼
        A_coo = A.tocoo()
        
        # æ„å»ºè¾¹ç´¢å¼•
        edges = np.vstack([A_coo.row, A_coo.col])
        
        # è·ç¦»è½¬æ¢ä¸ºæƒé‡ï¼ˆè·ç¦»è¶Šå°æƒé‡è¶Šå¤§ï¼‰
        distances = A_coo.data
        weights = 1.0 / (1.0 + distances)  # é¿å…é™¤é›¶
        
        edge_index = edges
        edge_weights = weights
        
        print(f"   âœ“ åŸºäºk-NNçš„è¾¹: {edge_index.shape[1]}")
        
        return edge_index, edge_weights
    
    def _build_hybrid_edges(self, df, X, k, threshold):
        """
        ç­–ç•¥4: æ··åˆç­–ç•¥ï¼ˆæ¨èï¼‰
        
        ç»“åˆå¤šç§è¾¹æ„å»ºæ–¹æ³•:
        1. å±æ€§è¾¹ï¼ˆæƒé‡é«˜ï¼‰
        2. k-NNè¾¹ï¼ˆç¡®ä¿è¿é€šæ€§ï¼‰
        3. é«˜ç›¸ä¼¼åº¦è¾¹ï¼ˆè¡¥å……ï¼‰
        """
        print("   ğŸ”„ ä½¿ç”¨æ··åˆè¾¹ç­–ç•¥...")
        
        all_edges = []
        all_weights = []
        
        # 1. å±æ€§è¾¹ï¼ˆæƒé‡ * 1.5ï¼Œä¼˜å…ˆçº§æœ€é«˜ï¼‰
        print("   â†’ æ·»åŠ å±æ€§è¾¹...")
        attr_edges, attr_weights = self._build_attribute_edges(df)
        all_edges.append(attr_edges)
        all_weights.append(attr_weights * 1.5)
        
        # 2. k-NNè¾¹ï¼ˆç¡®ä¿è¿é€šæ€§ï¼‰
        print(f"   â†’ æ·»åŠ k-NNè¾¹ (k={k})...")
        knn_edges, knn_weights = self._build_knn_edges(X, k)
        all_edges.append(knn_edges)
        all_weights.append(knn_weights)
        
        # 3. é«˜ç›¸ä¼¼åº¦è¾¹ï¼ˆé˜ˆå€¼è¾ƒé«˜ï¼Œè¡¥å……è¯­ä¹‰è¿æ¥ï¼‰
        print(f"   â†’ æ·»åŠ é«˜ç›¸ä¼¼åº¦è¾¹ (é˜ˆå€¼={threshold})...")
        sim_edges, sim_weights = self._build_similarity_edges(X, threshold)
        all_edges.append(sim_edges)
        all_weights.append(sim_weights)
        
        # åˆå¹¶æ‰€æœ‰è¾¹
        edge_index = np.hstack(all_edges)
        edge_weights = np.hstack(all_weights)
        
        # å»é‡ï¼ˆä¿ç•™æœ€å¤§æƒé‡ï¼‰
        edge_dict = {}
        for idx in range(edge_index.shape[1]):
            src, dst = edge_index[0, idx], edge_index[1, idx]
            weight = edge_weights[idx]
            
            key = (src, dst)
            if key in edge_dict:
                edge_dict[key] = max(edge_dict[key], weight)
            else:
                edge_dict[key] = weight
        
        # é‡æ„
        edges = []
        weights = []
        for (src, dst), weight in edge_dict.items():
            edges.append([src, dst])
            weights.append(weight)
        
        edge_index = np.array(edges).T
        edge_weights = np.array(weights)
        
        print(f"   âœ“ æ··åˆç­–ç•¥æ€»è¾¹æ•°: {len(edges)}")
        
        return edge_index, edge_weights
    
    def _create_pyg_data(self, X, y, edge_index, edge_weights, 
                        train_mask, val_mask, test_mask):
        """åˆ›å»ºPyTorch Geometric Dataå¯¹è±¡"""
        data = Data(
            x=torch.FloatTensor(X),
            edge_index=torch.LongTensor(edge_index),
            edge_attr=torch.FloatTensor(edge_weights).unsqueeze(1),  # [num_edges, 1]
            y=torch.LongTensor(y),
            train_mask=torch.BoolTensor(train_mask),
            val_mask=torch.BoolTensor(val_mask),
            test_mask=torch.BoolTensor(test_mask)
        )
        
        print(f"   âœ“ PyG Dataå¯¹è±¡åˆ›å»ºå®Œæˆ")
        print(f"   âœ“ èŠ‚ç‚¹ç‰¹å¾: {data.x.shape}")
        print(f"   âœ“ è¾¹ç´¢å¼•: {data.edge_index.shape}")
        print(f"   âœ“ è¾¹æƒé‡: {data.edge_attr.shape}")
        
        return data
    
    def _validate_graph(self, data):
        """éªŒè¯å›¾ç»“æ„çš„å®Œæ•´æ€§å’Œåˆç†æ€§"""
        print("\n" + "-"*70)
        print("ğŸ“Š å›¾ç»“æ„éªŒè¯")
        print("-"*70)
        
        # åŸºæœ¬ä¿¡æ¯
        print(f"\nåŸºæœ¬ä¿¡æ¯:")
        print(f"   èŠ‚ç‚¹æ•°: {data.num_nodes}")
        print(f"   è¾¹æ•°: {data.num_edges}")
        print(f"   ç‰¹å¾ç»´åº¦: {data.num_node_features}")
        print(f"   æ˜¯å¦æœ‰å‘: {data.is_directed()}")
        
        # æ£€æŸ¥è‡ªç¯
        has_self_loops = data.has_self_loops()
        print(f"   æ˜¯å¦æœ‰è‡ªç¯: {has_self_loops}")
        if has_self_loops:
            print("   â„¹ï¸ æç¤º: è‡ªç¯å¯ä»¥å¸®åŠ©ä¿ç•™èŠ‚ç‚¹è‡ªèº«ä¿¡æ¯")
        
        # æ£€æŸ¥å­¤ç«‹èŠ‚ç‚¹
        has_isolated = data.has_isolated_nodes()
        print(f"   æ˜¯å¦æœ‰å­¤ç«‹èŠ‚ç‚¹: {has_isolated}")
        if has_isolated:
            print("   âš ï¸ è­¦å‘Š: å­˜åœ¨å­¤ç«‹èŠ‚ç‚¹ï¼Œå¯èƒ½å½±å“è®­ç»ƒ")
        
        # è¿é€šæ€§åˆ†æ
        print(f"\nè¿é€šæ€§åˆ†æ:")
        from torch_geometric.utils import to_networkx
        import networkx as nx
        
        G = to_networkx(data, to_undirected=True)
        is_connected = nx.is_connected(G)
        num_components = nx.number_connected_components(G)
        
        print(f"   æ˜¯å¦è¿é€š: {is_connected}")
        print(f"   è¿é€šåˆ†é‡æ•°: {num_components}")
        
        if not is_connected:
            # åˆ†æå„è¿é€šåˆ†é‡å¤§å°
            components = list(nx.connected_components(G))
            component_sizes = [len(c) for c in components]
            print(f"   æœ€å¤§åˆ†é‡å¤§å°: {max(component_sizes)}")
            print(f"   æœ€å°åˆ†é‡å¤§å°: {min(component_sizes)}")
            print("   âš ï¸ è­¦å‘Š: å›¾ä¸è¿é€šï¼ŒGNNå¯èƒ½æ— æ³•æœ‰æ•ˆä¼ æ’­ä¿¡æ¯")
        
        # åº¦åˆ†å¸ƒ
        print(f"\nåº¦åˆ†å¸ƒ:")
        degrees = data.edge_index[0].bincount()
        print(f"   æœ€å°åº¦: {degrees.min().item()}")
        print(f"   æœ€å¤§åº¦: {degrees.max().item()}")
        print(f"   å¹³å‡åº¦: {degrees.float().mean().item():.2f}")
        print(f"   ä¸­ä½æ•°åº¦: {degrees.float().median().item():.2f}")
        
        # è¾¹æƒé‡åˆ†å¸ƒ
        if data.edge_attr is not None:
            print(f"\nè¾¹æƒé‡åˆ†å¸ƒ:")
            weights = data.edge_attr.squeeze()
            print(f"   æœ€å°æƒé‡: {weights.min().item():.3f}")
            print(f"   æœ€å¤§æƒé‡: {weights.max().item():.3f}")
            print(f"   å¹³å‡æƒé‡: {weights.mean().item():.3f}")
            print(f"   ä¸­ä½æ•°æƒé‡: {weights.median().item():.3f}")
        
        # æ•°æ®åˆ’åˆ†æ£€æŸ¥
        print(f"\næ•°æ®åˆ’åˆ†:")
        print(f"   è®­ç»ƒé›†: {data.train_mask.sum().item()} èŠ‚ç‚¹")
        print(f"   éªŒè¯é›†: {data.val_mask.sum().item()} èŠ‚ç‚¹")
        print(f"   æµ‹è¯•é›†: {data.test_mask.sum().item()} èŠ‚ç‚¹")
        
        # æ ‡ç­¾åˆ†å¸ƒ
        print(f"\næ ‡ç­¾åˆ†å¸ƒ:")
        print(f"   è®­ç»ƒé›†ç¦»èŒç‡: {data.y[data.train_mask].float().mean().item():.2%}")
        print(f"   éªŒè¯é›†ç¦»èŒç‡: {data.y[data.val_mask].float().mean().item():.2%}")
        print(f"   æµ‹è¯•é›†ç¦»èŒç‡: {data.y[data.test_mask].float().mean().item():.2%}")
        
        # ä¿å­˜éªŒè¯ç»Ÿè®¡
        self.stats.update({
            'is_connected': is_connected,
            'num_components': num_components,
            'has_isolated_nodes': has_isolated,
            'min_degree': int(degrees.min().item()),
            'max_degree': int(degrees.max().item()),
            'avg_degree': float(degrees.float().mean().item())
        })
        
        print("-"*70)
    
    def _save_statistics(self, strategy, k, threshold):
        """ä¿å­˜ç»Ÿè®¡ä¿¡æ¯"""
        self.stats['strategy'] = strategy
        self.stats['k'] = k
        self.stats['similarity_threshold'] = threshold
        
        stats_path = self.processed_dir / 'homo_graph_stats.json'
        with open(stats_path, 'w') as f:
            json.dump(self.stats, f, indent=2)
        
        print(f"\nğŸ“Š ç»Ÿè®¡ä¿¡æ¯å·²ä¿å­˜: {stats_path}")


def visualize_graph(data, save_path='outputs/homo_graph_visualization.png'):
    """
    å¯è§†åŒ–åŒæ„å›¾ï¼ˆå¯é€‰ï¼‰
    
    æ³¨æ„: å¯¹äºå¤§å›¾å¯èƒ½å¾ˆæ…¢
    """
    try:
        import matplotlib.pyplot as plt
        from torch_geometric.utils import to_networkx
        import networkx as nx
        
        print("\nğŸ¨ ç”Ÿæˆå›¾å¯è§†åŒ–...")
        
        # è½¬æ¢ä¸ºNetworkX
        G = to_networkx(data, to_undirected=True)
        
        # é‡‡æ ·ï¼ˆå¦‚æœèŠ‚ç‚¹å¤ªå¤šï¼‰
        if G.number_of_nodes() > 100:
            print("   èŠ‚ç‚¹æ•°è¿‡å¤šï¼Œéšæœºé‡‡æ ·100ä¸ªèŠ‚ç‚¹")
            nodes = list(G.nodes())[:100]
            G = G.subgraph(nodes)
        
        # ç»˜å›¾
        plt.figure(figsize=(12, 12))
        
        # å¸ƒå±€
        pos = nx.spring_layout(G, k=0.5, iterations=50)
        
        # èŠ‚ç‚¹é¢œè‰²ï¼ˆåŸºäºæ ‡ç­¾ï¼‰
        node_colors = ['red' if data.y[i].item() == 1 else 'lightblue' 
                      for i in G.nodes()]
        
        # ç»˜åˆ¶
        nx.draw_networkx_nodes(G, pos, node_color=node_colors, 
                              node_size=300, alpha=0.7)
        nx.draw_networkx_edges(G, pos, alpha=0.2)
        
        plt.title("Homogeneous Graph Visualization\n(Red=Turnover, Blue=Stay)")
        plt.axis('off')
        plt.tight_layout()
        
        # ä¿å­˜
        Path(save_path).parent.mkdir(parents=True, exist_ok=True)
        plt.savefig(save_path, dpi=150, bbox_inches='tight')
        plt.close()
        
        print(f"   âœ… å¯è§†åŒ–å·²ä¿å­˜: {save_path}")
        
    except ImportError:
        print("   âš ï¸ è·³è¿‡å¯è§†åŒ–ï¼ˆéœ€è¦networkxå’Œmatplotlibï¼‰")
    except Exception as e:
        print(f"   âš ï¸ å¯è§†åŒ–å¤±è´¥: {e}")


def main():
    """ä¸»å‡½æ•°ï¼šæ„å»ºåŒæ„å›¾"""
    print("\n" + "="*70)
    print("ğŸš€ åŒæ„å›¾æ„å»ºè„šæœ¬")
    print("="*70)
    
    # åˆ›å»ºæ„å»ºå™¨
    builder = HomogeneousGraphBuilder(data_dir='data')
    
    # æ„å»ºåŒæ„å›¾ï¼ˆä½¿ç”¨æ··åˆç­–ç•¥ï¼‰
    data = builder.build(
        strategy='hybrid',      # æ¨èä½¿ç”¨æ··åˆç­–ç•¥
        k=10,                   # k-NNçš„kå€¼
        similarity_threshold=0.6  # ç›¸ä¼¼åº¦é˜ˆå€¼
    )
    
    # å¯é€‰ï¼šå¯è§†åŒ–
    # visualize_graph(data)
    
    # æµ‹è¯•åŠ è½½
    print("\nğŸ§ª æµ‹è¯•åŠ è½½...")
    loaded_data = torch.load('data/processed/homo_graph.pt')
    print(f"   âœ… åŠ è½½æˆåŠŸï¼èŠ‚ç‚¹æ•°={loaded_data.num_nodes}, è¾¹æ•°={loaded_data.num_edges}")
    
    print("\n" + "="*70)
    print("âœ… å…¨éƒ¨å®Œæˆï¼")
    print("="*70)
    print("\nä¸‹ä¸€æ­¥: python src/models/gcn.py")
    
    return data


if __name__ == '__main__':
    main()