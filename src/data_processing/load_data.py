import pandas as pd
import numpy as np
from pathlib import Path

class DataLoader:
    """åŸå§‹æ•°æ®åŠ è½½å™¨"""
    
    def __init__(self, data_path: str):
        """
        Args:
            data_path: åŸå§‹CSVæ–‡ä»¶è·¯å¾„
        """
        self.data_path = Path(data_path)
        self.df = None
        
    def load(self, encoding='gbk', skiprows=1):
        """
        åŠ è½½CSVæ•°æ®
        
        Args:
            encoding: æ–‡ä»¶ç¼–ç 
            skiprows: è·³è¿‡çš„è¡Œæ•°ï¼ˆé€šå¸¸è·³è¿‡é‡å¤è¡¨å¤´ï¼‰
            
        Returns:
            pd.DataFrame: åŠ è½½çš„æ•°æ®æ¡†
        """
        print(f"ğŸ”„ æ­£åœ¨åŠ è½½æ•°æ®: {self.data_path}")
        
        try:
            self.df = pd.read_csv(self.data_path, encoding=encoding, skiprows=skiprows)
            print(f"âœ… æˆåŠŸåŠ è½½ {len(self.df)} æ¡æ ·æœ¬, {len(self.df.columns)} ä¸ªå­—æ®µ")
            return self.df
        except Exception as e:
            print(f"âŒ åŠ è½½å¤±è´¥: {e}")
            raise
    
    def get_basic_info(self):
        """è·å–æ•°æ®é›†åŸºç¡€ä¿¡æ¯"""
        if self.df is None:
            raise ValueError("è¯·å…ˆè°ƒç”¨load()æ–¹æ³•åŠ è½½æ•°æ®")
        
        info = {
            'n_samples': len(self.df),
            'n_features': len(self.df.columns),
            'memory_usage': f"{self.df.memory_usage(deep=True).sum() / 1024**2:.2f} MB",
            'columns': list(self.df.columns),
            'dtypes': self.df.dtypes.value_counts().to_dict()
        }
        
        return info
    
    def get_missing_stats(self):
        """è·å–ç¼ºå¤±å€¼ç»Ÿè®¡"""
        if self.df is None:
            raise ValueError("è¯·å…ˆè°ƒç”¨load()æ–¹æ³•åŠ è½½æ•°æ®")
        
        missing = self.df.isnull().sum()
        missing_pct = (missing / len(self.df) * 100).round(2)
        
        stats = pd.DataFrame({
            'missing_count': missing,
            'missing_pct': missing_pct
        })
        
        return stats[stats['missing_count'] > 0].sort_values('missing_count', ascending=False)
    
    def get_column_info(self, column_name: str):
        """è·å–ç‰¹å®šåˆ—çš„è¯¦ç»†ä¿¡æ¯"""
        if self.df is None:
            raise ValueError("è¯·å…ˆè°ƒç”¨load()æ–¹æ³•åŠ è½½æ•°æ®")
        
        col = self.df[column_name]
        
        info = {
            'dtype': str(col.dtype),
            'n_unique': col.nunique(),
            'n_missing': col.isnull().sum(),
            'missing_pct': f"{col.isnull().sum() / len(col) * 100:.2f}%"
        }
        
        # è·å–å€¼åˆ†å¸ƒ
        if col.nunique() < 50:
            info['value_counts'] = col.value_counts().to_dict()
        else:
            info['sample_values'] = col.dropna().head(5).tolist()
        
        # æ•°å€¼å‹ç»Ÿè®¡
        if pd.api.types.is_numeric_dtype(col):
            info['statistics'] = {
                'mean': col.mean(),
                'std': col.std(),
                'min': col.min(),
                'max': col.max(),
                'median': col.median()
            }
        
        return info


def main():
    """æ¼”ç¤ºæ•°æ®åŠ è½½"""
    # åŠ è½½æ•°æ®
    loader = DataLoader('/Users/yu/code/code2510/gnn/data/raw/originaldata.csv')
    df = loader.load()
    
    # åŸºç¡€ä¿¡æ¯
    print("\n" + "="*80)
    print("åŸºç¡€ä¿¡æ¯")
    print("="*80)
    info = loader.get_basic_info()
    for key, value in info.items():
        if key != 'columns':
            print(f"{key}: {value}")
    
    # ç¼ºå¤±å€¼ç»Ÿè®¡
    print("\n" + "="*80)
    print("ç¼ºå¤±å€¼ç»Ÿè®¡")
    print("="*80)
    missing = loader.get_missing_stats()
    if len(missing) > 0:
        print(missing)
    else:
        print("âœ… æ— ç¼ºå¤±å€¼ï¼")
    
    # æŸ¥çœ‹å…³é”®åˆ—
    print("\n" + "="*80)
    print("å…³é”®åˆ—ä¿¡æ¯")
    print("="*80)
    
    key_columns = ['Q30', 'Q3', 'Q4']
    for col in key_columns:
        print(f"\nã€{col}ã€‘")
        col_info = loader.get_column_info(col)
        for k, v in col_info.items():
            print(f"  {k}: {v}")


if __name__ == '__main__':
    main()