"""
SMOTEæ•°æ®å¢å¼º
é€šè¿‡åˆæˆæ–°æ ·æœ¬æ¥å¹³è¡¡è®­ç»ƒé›†
"""

import torch
import numpy as np
from sklearn.neighbors import NearestNeighbors
import sys
sys.path.insert(0, 'src/models')

from gcn import create_gcn_model
from trainer2 import quick_train
from evaluator2 import GCNEvaluator


def smote_oversample(features, labels, train_mask, k=5, target_ratio=0.3):
    """
    SMOTEè¿‡é‡‡æ ·
    
    Args:
        features: èŠ‚ç‚¹ç‰¹å¾
        labels: æ ‡ç­¾
        train_mask: è®­ç»ƒé›†mask
        k: æœ€è¿‘é‚»æ•°é‡
        target_ratio: ç›®æ ‡æ­£æ ·æœ¬æ¯”ä¾‹
        
    Returns:
        å¢å¼ºåçš„features, labels, train_mask
    """
    print("\næ‰§è¡ŒSMOTEæ•°æ®å¢å¼º...")
    
    # è·å–è®­ç»ƒé›†ä¸­çš„æ­£è´Ÿæ ·æœ¬
    train_features = features[train_mask].numpy()
    train_labels = labels[train_mask].numpy()
    
    pos_indices = np.where(train_labels == 1)[0]
    neg_indices = np.where(train_labels == 0)[0]
    
    num_pos = len(pos_indices)
    num_neg = len(neg_indices)
    num_train = len(train_labels)
    
    print(f"   åŸå§‹æ­£æ ·æœ¬: {num_pos} ({num_pos/num_train:.1%})")
    print(f"   åŸå§‹è´Ÿæ ·æœ¬: {num_neg} ({num_neg/num_train:.1%})")
    
    # è®¡ç®—éœ€è¦åˆæˆçš„æ ·æœ¬æ•°
    num_needed = int(num_train * target_ratio / (1 - target_ratio)) - num_pos
    
    if num_needed <= 0:
        print(f"   æ— éœ€å¢å¼ºï¼Œå·²è¾¾åˆ°ç›®æ ‡æ¯”ä¾‹")
        return features, labels, train_mask
    
    print(f"   éœ€è¦åˆæˆ: {num_needed} ä¸ªæ­£æ ·æœ¬")
    
    # ä½¿ç”¨KNNæ‰¾æœ€è¿‘é‚»
    pos_features = train_features[pos_indices]
    nbrs = NearestNeighbors(n_neighbors=min(k+1, len(pos_features))).fit(pos_features)
    
    # åˆæˆæ–°æ ·æœ¬
    synthetic_features = []
    for _ in range(num_needed):
        # éšæœºé€‰æ‹©ä¸€ä¸ªæ­£æ ·æœ¬
        idx = np.random.randint(0, len(pos_features))
        sample = pos_features[idx]
        
        # æ‰¾åˆ°kä¸ªæœ€è¿‘é‚»
        distances, indices = nbrs.kneighbors([sample])
        # éšæœºé€‰æ‹©ä¸€ä¸ªé‚»å±…ï¼ˆæ’é™¤è‡ªå·±ï¼‰
        neighbor_idx = np.random.choice(indices[0][1:])
        neighbor = pos_features[neighbor_idx]
        
        # åœ¨ä¸¤ä¸ªæ ·æœ¬ä¹‹é—´æ’å€¼
        alpha = np.random.random()
        synthetic = sample + alpha * (neighbor - sample)
        synthetic_features.append(synthetic)
    
    synthetic_features = np.array(synthetic_features)
    
    # åˆå¹¶åŸå§‹æ•°æ®å’Œåˆæˆæ•°æ®
    # æ³¨æ„ï¼šåˆæˆçš„èŠ‚ç‚¹ä¸åœ¨å›¾ä¸­ï¼Œæ‰€ä»¥ä»–ä»¬çš„é‚»å±…ä¿¡æ¯ä¼šæ˜¯éšæœºçš„
    # è¿™æ˜¯ä¸€ä¸ªç®€åŒ–ç‰ˆæœ¬ï¼Œå®Œæ•´ç‰ˆæœ¬éœ€è¦é‡æ–°æ„å»ºå›¾
    
    print(f"   âœ“ åˆæˆå®Œæˆ: {len(synthetic_features)} ä¸ªæ–°æ ·æœ¬")
    print(f"   æ–°æ­£æ ·æœ¬æ¯”ä¾‹: {(num_pos + num_needed)/(num_train + num_needed):.1%}")
    
    # æ‰©å±•ç‰¹å¾çŸ©é˜µ
    features_extended = torch.cat([
        features,
        torch.from_numpy(synthetic_features).float()
    ], dim=0)
    
    # æ‰©å±•æ ‡ç­¾
    labels_extended = torch.cat([
        labels,
        torch.ones(len(synthetic_features), dtype=labels.dtype)
    ])
    
    # æ‰©å±•train_mask
    train_mask_extended = torch.cat([
        train_mask,
        torch.ones(len(synthetic_features), dtype=torch.bool)
    ])
    
    return features_extended, labels_extended, train_mask_extended


print("\n" + "="*70)
print("ğŸ”„ SMOTEæ•°æ®å¢å¼ºè®­ç»ƒ")
print("="*70)

# åŠ è½½æ•°æ®
print("\n1. åŠ è½½åŸå§‹æ•°æ®...")
data = torch.load('data/processed/homo_graph.pt')
print(f"   èŠ‚ç‚¹: {data.num_nodes}")

# SMOTEå¢å¼º
features_aug, labels_aug, train_mask_aug = smote_oversample(
    data.x,
    data.y,
    data.train_mask,
    k=5,
    target_ratio=0.25  # ç›®æ ‡ï¼š25%æ­£æ ·æœ¬
)

# åˆ›å»ºå¢å¼ºåçš„æ•°æ®å¯¹è±¡
# æ³¨æ„ï¼šè¿™é‡Œæˆ‘ä»¬ä¿æŒåŸæ¥çš„å›¾ç»“æ„ï¼Œæ–°èŠ‚ç‚¹ä¼šæœ‰éšæœºçš„é‚»å±…
from torch_geometric.data import Data

# æ‰©å±•è¾¹ç´¢å¼•ï¼ˆæ–°èŠ‚ç‚¹çš„è¾¹ï¼‰
num_new = len(labels_aug) - data.num_nodes
if num_new > 0:
    print(f"\n2. ä¸º{num_new}ä¸ªæ–°èŠ‚ç‚¹åˆ›å»ºè¾¹...")
    # ç®€åŒ–ç‰ˆæœ¬ï¼šæ¯ä¸ªæ–°èŠ‚ç‚¹éšæœºè¿æ¥åˆ°kä¸ªåŸå§‹èŠ‚ç‚¹
    k_connect = 10
    new_edges = []
    for i in range(num_new):
        new_node_idx = data.num_nodes + i
        # éšæœºé€‰æ‹©kä¸ªåŸå§‹èŠ‚ç‚¹è¿æ¥
        targets = np.random.choice(data.num_nodes, k_connect, replace=False)
        for target in targets:
            new_edges.append([new_node_idx, target])
            new_edges.append([target, new_node_idx])  # æ— å‘å›¾
    
    new_edges = torch.tensor(new_edges, dtype=torch.long).t()
    edge_index_aug = torch.cat([data.edge_index, new_edges], dim=1)
    print(f"   âœ“ æ–°å¢è¾¹: {new_edges.shape[1]}")
else:
    edge_index_aug = data.edge_index

# åˆ›å»ºå¢å¼ºæ•°æ®å¯¹è±¡
data_aug = Data(
    x=features_aug,
    edge_index=edge_index_aug,
    y=labels_aug,
    train_mask=train_mask_aug,
    val_mask=torch.cat([data.val_mask, torch.zeros(num_new, dtype=torch.bool)]),
    test_mask=torch.cat([data.test_mask, torch.zeros(num_new, dtype=torch.bool)])
)

print(f"\nå¢å¼ºåæ•°æ®:")
print(f"   èŠ‚ç‚¹: {data_aug.num_nodes} (åŸ: {data.num_nodes}, æ–°: {num_new})")
print(f"   è¾¹: {data_aug.num_edges} (åŸ: {data.num_edges})")
print(f"   è®­ç»ƒé›†: {data_aug.train_mask.sum()} (åŸ: {data.train_mask.sum()})")

# åˆ›å»ºæ¨¡å‹
print("\n3. åˆ›å»ºæ¨¡å‹...")
model = create_gcn_model(
    in_channels=data_aug.num_node_features,
    architecture='default',
    dropout=0.5
)

# è®­ç»ƒ
print("\n4. è®­ç»ƒæ¨¡å‹...")
trainer, history = quick_train(
    model=model,
    data=data_aug,
    epochs=200,
    lr=0.01,
    weight_decay=5e-4,
    early_stopping_patience=20,
    device='cpu',
    save_dir='outputs/models_smote'
)

# è¯„ä¼°ï¼ˆåªåœ¨åŸå§‹æµ‹è¯•é›†ä¸Šï¼‰
print("\n5. è¯„ä¼°ï¼ˆåŸå§‹æµ‹è¯•é›†ï¼‰...")
evaluator = GCNEvaluator(model, data_aug)

# æ‰‹åŠ¨è¯„ä¼°åŸå§‹æµ‹è¯•é›†
test_loss, test_acc, test_f1 = trainer.evaluate(data.test_mask)
print(f"\næµ‹è¯•é›†ç»“æœ:")
print(f"   F1-Score:  {test_f1:.4f}")
print(f"   Accuracy:  {test_acc:.4f}")

# å®Œæ•´è¯„ä¼°
results = evaluator.full_evaluation(save_dir='outputs/evaluation_smote')

print("\n" + "="*70)
print("âœ… SMOTEå¢å¼ºè®­ç»ƒå®Œæˆï¼")
print("="*70)
print(f"\nç»“æœä¿å­˜åœ¨: outputs/evaluation_smote/")
