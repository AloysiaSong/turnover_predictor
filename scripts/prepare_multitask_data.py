"""
å‡†å¤‡å¤šä»»åŠ¡æ•°æ®ï¼šæ·»åŠ å²—ä½åå¥½æ’åº
=====================================
ä»åŸå§‹CSVä¸­æå–7ä¸ªæƒ…æ™¯ä»»åŠ¡çš„å²—ä½åå¥½ï¼Œæ·»åŠ åˆ°å›¾æ•°æ®ä¸­
"""

import pandas as pd
import torch
from pathlib import Path
import numpy as np
import re


def prepare_preference_data(
    original_csv='data/raw/originaldata.csv',
    graph_path='data/processed/homo_graph.pt',
    output_path='data/processed/homo_graph_with_preferences.pt'
):
    """
    å‡†å¤‡å¸¦æœ‰å²—ä½åå¥½çš„å›¾æ•°æ®
    
    Args:
        original_csv: åŸå§‹æ•°æ®CSVè·¯å¾„
        graph_path: ç°æœ‰å›¾æ•°æ®è·¯å¾„
        output_path: è¾“å‡ºè·¯å¾„
    """
    print("\n" + "="*70)
    print("ğŸ“‹ å‡†å¤‡å¤šä»»åŠ¡æ•°æ®ï¼šæ·»åŠ å²—ä½åå¥½")
    print("="*70)
    
    # 1. åŠ è½½åŸå§‹CSV
    print("\n1. åŠ è½½åŸå§‹æ•°æ®...")
    
    # å°è¯•å¤šç§ç¼–ç 
    encodings = ['utf-8', 'gbk', 'gb2312', 'gb18030', 'latin1', 'iso-8859-1']
    df = None
    
    for encoding in encodings:
        try:
            df = pd.read_csv(original_csv, encoding=encoding)
            print(f"   âœ“ ä½¿ç”¨ç¼–ç  {encoding} æˆåŠŸåŠ è½½")
            break
        except UnicodeDecodeError:
            continue
        except Exception as e:
            print(f"   å°è¯•ç¼–ç  {encoding} å¤±è´¥: {e}")
            continue
    
    if df is None:
        raise ValueError("æ— æ³•ç”¨ä»»ä½•ç¼–ç è¯»å–CSVï¼Œè¯·æ£€æŸ¥æ–‡ä»¶")
    
    print(f"   âœ“ åŠ è½½ {len(df)} æ¡è®°å½•")
    print(f"   âœ“ åˆ—æ•°: {len(df.columns)}")
    
    # 2. æå–å²—ä½åå¥½åˆ—
    print("\n2. æå–å²—ä½åå¥½æ•°æ®...")
    
    # æ‰“å°æ‰€æœ‰åˆ—åä¾›å‚è€ƒ
    print(f"\n   CSVåŒ…å« {len(df.columns)} åˆ—")
    print(f"   å‰20åˆ—åç§°:")
    for i, col in enumerate(df.columns[:20]):
        print(f"      {i+1}. {col}")
    
    if len(df.columns) > 20:
        print(f"   ... (è¿˜æœ‰ {len(df.columns)-20} åˆ—)")
    
    # æŸ¥æ‰¾åå¥½ç›¸å…³çš„åˆ—
    preference_cols = []
    
    # æ–¹æ³•1: ç›´æ¥æŸ¥æ‰¾åŒ…å«æƒ…æ™¯(S)å’Œå²—ä½(P)çš„åˆ—
    # ä¾‹å¦‚: S1P1, S1P2, ..., S7P7 æˆ– S1_P1, scenario1_pos1 ç­‰
    for scenario_idx in range(1, 8):  # 7ä¸ªæƒ…æ™¯
        scenario_patterns = [
            f'S{scenario_idx}',
            f's{scenario_idx}',
            f'scenario{scenario_idx}',
            f'Scenario{scenario_idx}',
            f'æƒ…æ™¯{scenario_idx}',
        ]
        
        for pattern in scenario_patterns:
            scenario_cols = [col for col in df.columns if pattern in col]
            if len(scenario_cols) > 0:
                preference_cols.extend(scenario_cols)
                break
    
    if len(preference_cols) == 0:
        # æ–¹æ³•2: æŸ¥æ‰¾rankæˆ–preferå…³é”®è¯
        preference_cols = [col for col in df.columns 
                        if 'rank' in col.lower() or 
                            'prefer' in col.lower() or
                            'choice' in col.lower() or
                            'select' in col.lower()]
    
    print(f"\n   æ‰¾åˆ°å¯èƒ½çš„åå¥½ç›¸å…³åˆ—æ•°: {len(preference_cols)}")
    if len(preference_cols) > 0:
        print(f"   åå¥½åˆ—ç¤ºä¾‹:")
        for col in preference_cols[:10]:
            print(f"      - {col}")
    else:
        print("\n   âš ï¸  æœªæ‰¾åˆ°æ˜ç¡®çš„åå¥½åˆ—")
        print("\n   ğŸ’¡ è¯·æ£€æŸ¥ä»¥ä¸‹åˆ—åï¼Œæ‰¾å‡ºå²—ä½åå¥½ç›¸å…³çš„åˆ—:")
        print("   " + "="*60)
        for i, col in enumerate(df.columns):
            print(f"   {i+1:3d}. {col}")
        print("   " + "="*60)
    
    # ä»CSVæå–çœŸå®åå¥½æ•°æ®ï¼ˆå°½æœ€å¤§åŠªåŠ›ï¼‰
    print("\n   å°è¯•ä»CSVæå–çœŸå®åå¥½æ•°æ®...")
    
    n_samples = len(df)
    n_scenarios = 7
    
    # åˆå§‹åŒ–åå¥½çŸ©é˜µ (æ ·æœ¬æ•°, æƒ…æ™¯æ•°)
    preference_ranks = np.zeros((n_samples, n_scenarios), dtype=int)
    extracted = False
    
    # ä¼˜å…ˆå°è¯•: è¯†åˆ«â€œæƒ…æ™¯é€‰æ‹©ä»»åŠ¡â€åˆ—ï¼ˆæ’é™¤å²—ä½ä¿¡æ¯æè¿°ï¼‰
    scenario_choice_cols = [
        col for col in df.columns
        if 'æƒ…æ™¯é€‰æ‹©ä»»åŠ¡' in col
        and 'å²—ä½ä¿¡æ¯' not in col
        and any(keyword in col for keyword in ['é€‰æ‹©', 'è¯·é€‰æ‹©', 'é€‰æ‹©ä¸€ä»½', 'é€‰æ‹©ä¸€ä»½ä½ æ›´æ„¿æ„'])
    ]
    
    def scenario_sort_key(column_name: str) -> int:
        match = re.search(r'ä»»åŠ¡(\d+)', column_name)
        return int(match.group(1)) if match else 999
    
    scenario_choice_cols = sorted(set(scenario_choice_cols), key=scenario_sort_key)
    
    if len(scenario_choice_cols) >= n_scenarios:
        print(f"   âœ“ æ‰¾åˆ° {len(scenario_choice_cols)} ä¸ªæƒ…æ™¯é€‰æ‹©ä»»åŠ¡åˆ—")
        print(f"   ç¤ºä¾‹åˆ—å:")
        for col in scenario_choice_cols[:3]:
            print(f"      - {col}")
        
        for i, col_name in enumerate(scenario_choice_cols[:n_scenarios]):
            col_data = df[col_name].values
            try:
                numeric_data = pd.to_numeric(col_data, errors='coerce')
                if numeric_data.isna().all():
                    mapping = {
                        'A': 1, 'B': 2, 'C': 3, 'D': 4, 'E': 5, 'F': 6, 'G': 7,
                        'a': 1, 'b': 2, 'c': 3, 'd': 4, 'e': 5, 'f': 6, 'g': 7,
                        'å²—ä½A': 1, 'å²—ä½B': 2
                    }
                    numeric_data = pd.Series(col_data).map(mapping).fillna(1).values
                preference_ranks[:, i] = numeric_data.astype(int)
            except Exception:
                print(f"   âš ï¸  åˆ— {col_name} è½¬æ¢å¤±è´¥ï¼Œä½¿ç”¨éšæœºå€¼")
                preference_ranks[:, i] = np.random.randint(1, 8, size=len(df))
        
        extracted = True
        print(f"   âœ“ ä»æƒ…æ™¯é€‰æ‹©ä»»åŠ¡æå–åå¥½æ•°æ®")
    
    # å…¶æ¬¡å°è¯•: å‡è®¾åˆ—åæ ¼å¼ä¸º S1, S2, ..., S7
    if not extracted:
        success = True
        for i in range(n_scenarios):
            col_candidates = [
                f'S{i+1}',
                f's{i+1}',
                f'scenario{i+1}',
                f'Scenario{i+1}',
            ]
            
            found = False
            for col_name in col_candidates:
                if col_name in df.columns:
                    preference_ranks[:, i] = df[col_name].values
                    found = True
                    break
            
            if not found:
                success = False
                break
        
        if success:
            extracted = True
            print("   âœ“ ä½¿ç”¨ S{1..7} æ¨¡å¼æå–åå¥½æ•°æ®")
    
    # å†æ¬¡å°è¯•: ä½¿ç”¨é¢„å…ˆæ”¶é›†çš„åŒ¹é…åˆ—
    if not extracted and len(preference_cols) >= n_scenarios:
        for i, col_name in enumerate(preference_cols[:n_scenarios]):
            preference_ranks[:, i] = df[col_name].values
        extracted = True
        print("   âœ“ ä½¿ç”¨åŒ¹é…çš„åå¥½åˆ—æå–æ•°æ®")
    
    # æ ¡éªŒç»“æœ
    if extracted:
        print(f"   âœ“ æå–åå¥½çŸ©é˜µ: {preference_ranks.shape}")
        print(f"   âœ“ æ•°æ®èŒƒå›´: [{preference_ranks.min()}, {preference_ranks.max()}]")
        
        if preference_ranks.min() < 1 or preference_ranks.max() > 7:
            print(f"   âš ï¸  è­¦å‘Š: åå¥½å€¼ä¸åœ¨1-7èŒƒå›´å†…ï¼")
            print(f"   âš ï¸  å°†ä½¿ç”¨æ¨¡æ‹Ÿæ•°æ®ä»£æ›¿")
            extracted = False
    
    # å¦‚æœä»æœªæå–æˆåŠŸï¼Œåˆ™ä½¿ç”¨æ¨¡æ‹Ÿæ•°æ®
    if not extracted:
        print(f"   âš ï¸  æ— æ³•è‡ªåŠ¨æå–åå¥½æ•°æ®")
        print(f"   ğŸ”§ ä½¿ç”¨æ¨¡æ‹Ÿæ•°æ®...")
        
        np.random.seed(42)
        preference_ranks = np.zeros((n_samples, n_scenarios), dtype=int)
        for i in range(n_samples):
            preference_ranks[i] = np.random.permutation(n_scenarios) + 1
        
        print(f"   âœ“ åˆ›å»ºæ¨¡æ‹Ÿåå¥½çŸ©é˜µ: {preference_ranks.shape}")
    
    # 3. åŠ è½½ç°æœ‰å›¾æ•°æ®
    print("\n3. åŠ è½½ç°æœ‰å›¾æ•°æ®...")
    data = torch.load(graph_path)
    print(f"   âœ“ èŠ‚ç‚¹: {data.x.shape[0]}")
    print(f"   âœ“ ç‰¹å¾: {data.x.shape[1]}")
    print(f"   âœ“ è¾¹: {data.edge_index.shape[1]}")
    
    # 4. æ·»åŠ åå¥½æ•°æ®
    print("\n4. æ·»åŠ å²—ä½åå¥½æ•°æ®åˆ°å›¾...")
    
    # ç¡®ä¿æ ·æœ¬æ•°åŒ¹é…ï¼ˆCSVå¯èƒ½æ¯”å›¾å¤š1è¡Œè¡¨å¤´æˆ–æ— æ•ˆæ•°æ®ï¼‰
    if preference_ranks.shape[0] != data.x.shape[0]:
        print(f"   âš ï¸  æ ·æœ¬æ•°ä¸åŒ¹é…: CSV={preference_ranks.shape[0]}, Graph={data.x.shape[0]}")
        
        if preference_ranks.shape[0] == data.x.shape[0] + 1:
            print(f"   âœ“ CSVæ¯”å›¾å¤š1è¡Œï¼Œç§»é™¤æœ€åä¸€è¡Œ")
            preference_ranks = preference_ranks[:-1]
        elif preference_ranks.shape[0] > data.x.shape[0]:
            print(f"   âœ“ æˆªå–å‰{data.x.shape[0]}è¡Œ")
            preference_ranks = preference_ranks[:data.x.shape[0]]
        else:
            raise ValueError(f"CSVè¡Œæ•°({preference_ranks.shape[0]})å°‘äºå›¾èŠ‚ç‚¹æ•°({data.x.shape[0]})")
    
    # æ·»åŠ åˆ°å›¾æ•°æ®
    data.preference_ranks = torch.from_numpy(preference_ranks).long()
    
    print(f"   âœ“ æ·»åŠ  preference_ranks: {data.preference_ranks.shape}")
    print(f"   âœ“ æ•°æ®ç±»å‹: {data.preference_ranks.dtype}")
    print(f"   âœ“ å–å€¼èŒƒå›´: [{data.preference_ranks.min()}, {data.preference_ranks.max()}]")
    
    # 5. éªŒè¯æ•°æ®
    print("\n5. éªŒè¯åå¥½æ•°æ®...")
    
    # æ£€æŸ¥æ˜¯å¦æ‰€æœ‰æ’åºéƒ½æ˜¯1-7
    unique_ranks = torch.unique(data.preference_ranks)
    print(f"   å”¯ä¸€æ’åºå€¼: {unique_ranks.tolist()}")
    
    # éšæœºæŠ½æ ·å±•ç¤º
    print("\n   éšæœºæ ·æœ¬å±•ç¤º:")
    sample_indices = np.random.choice(data.x.shape[0], min(5, data.x.shape[0]), replace=False)
    for idx in sample_indices:
        ranks = data.preference_ranks[idx].numpy()
        print(f"   å‘˜å·¥ {idx}: {ranks}")
    
    # 6. ä¿å­˜
    print(f"\n6. ä¿å­˜æ–°çš„å›¾æ•°æ®...")
    output_path = Path(output_path)
    output_path.parent.mkdir(parents=True, exist_ok=True)
    
    torch.save(data, output_path)
    print(f"   âœ“ ä¿å­˜è‡³: {output_path}")
    
    # 7. éªŒè¯ä¿å­˜
    print("\n7. éªŒè¯ä¿å­˜çš„æ•°æ®...")
    data_loaded = torch.load(output_path)
    assert hasattr(data_loaded, 'preference_ranks'), "preference_ranksä¸¢å¤±"
    print(f"   âœ“ éªŒè¯æˆåŠŸ")
    print(f"   âœ“ preference_ranks shape: {data_loaded.preference_ranks.shape}")
    
    print("\n" + "="*70)
    print("âœ… æ•°æ®å‡†å¤‡å®Œæˆ!")
    print("="*70)
    print(f"\nğŸ“Š æ•°æ®ç»Ÿè®¡:")
    print(f"   èŠ‚ç‚¹æ•°: {data.x.shape[0]}")
    print(f"   ç‰¹å¾ç»´åº¦: {data.x.shape[1]}")
    print(f"   å²—ä½æ•°: {data.preference_ranks.shape[1]}")
    print(f"   è¾¹æ•°: {data.edge_index.shape[1]}")
    print(f"\nğŸ’¾ è¾“å‡ºæ–‡ä»¶: {output_path}")
    print("="*70 + "\n")
    
    return data


def create_mock_preference_data(graph_path, output_path):
    """
    åˆ›å»ºæ¨¡æ‹Ÿçš„åå¥½æ•°æ®ï¼ˆç”¨äºå¿«é€Ÿæµ‹è¯•ï¼‰
    """
    print("\nğŸ”§ åˆ›å»ºæ¨¡æ‹Ÿåå¥½æ•°æ®...")
    
    # åŠ è½½å›¾
    data = torch.load(graph_path)
    n_samples = data.x.shape[0]
    n_positions = 7
    
    # ç”Ÿæˆéšæœºä½†åˆç†çš„åå¥½æ’åº
    np.random.seed(42)
    preference_ranks = np.zeros((n_samples, n_positions), dtype=int)
    
    for i in range(n_samples):
        # æ¯ä¸ªå‘˜å·¥å¯¹7ä¸ªå²—ä½çš„éšæœºæ’åº
        preference_ranks[i] = np.random.permutation(n_positions) + 1  # 1-7
    
    # æ·»åŠ åˆ°å›¾
    data.preference_ranks = torch.from_numpy(preference_ranks).long()
    
    # ä¿å­˜
    torch.save(data, output_path)
    
    print(f"   âœ“ æ¨¡æ‹Ÿæ•°æ®å·²åˆ›å»º: {output_path}")
    print(f"   âœ“ preference_ranks: {data.preference_ranks.shape}")
    
    return data


if __name__ == '__main__':
    import argparse
    
    parser = argparse.ArgumentParser(description='å‡†å¤‡å²—ä½åå¥½æ•°æ®')
    parser.add_argument('--mode', type=str, default='real',
                       choices=['real', 'mock'],
                       help='real=ä»CSVæå–, mock=ç”Ÿæˆæ¨¡æ‹Ÿæ•°æ®')
    parser.add_argument('--original-csv', type=str,
                       default='data/raw/originaldata.csv',
                       help='åŸå§‹CSVè·¯å¾„')
    parser.add_argument('--graph-path', type=str,
                       default='data/processed/homo_graph.pt',
                       help='ç°æœ‰å›¾æ•°æ®è·¯å¾„')
    parser.add_argument('--output-path', type=str,
                       default='data/processed/homo_graph_with_preferences.pt',
                       help='è¾“å‡ºè·¯å¾„')
    
    args = parser.parse_args()
    
    if args.mode == 'real':
        # ä»çœŸå®CSVæå–
        try:
            data = prepare_preference_data(
                args.original_csv,
                args.graph_path,
                args.output_path
            )
        except Exception as e:
            print(f"\nâŒ é”™è¯¯: {e}")
            print("\nğŸ’¡ æç¤º: å¦‚æœCSVåˆ—åä¸æ˜ç¡®ï¼Œè¯·å…ˆä½¿ç”¨ --mode mock åˆ›å»ºæµ‹è¯•æ•°æ®")
    
    elif args.mode == 'mock':
        # åˆ›å»ºæ¨¡æ‹Ÿæ•°æ®
        data = create_mock_preference_data(
            args.graph_path,
            args.output_path
        )
    
    print("\nğŸ¯ ä¸‹ä¸€æ­¥:")
    print("   è¿è¡Œå¤šä»»åŠ¡è®­ç»ƒ:")
    print(f"   python scripts/train_gcn_v3.py --data-path {args.output_path}")
