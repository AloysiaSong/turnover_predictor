"""
GCNè®­ç»ƒè„šæœ¬ï¼ˆå®Œæ•´ç‰ˆï¼‰
====================
åŠŸèƒ½ï¼š
1. EdgeDropout + FeatureDropout
2. ç‰¹å¾æ‰©å±•ï¼ˆåˆ†ç®±+äº¤äº’é¡¹ï¼‰
3. Val_AUCPRæ—©åœ
4. é˜ˆå€¼ä¼˜åŒ–ï¼ˆä»…åœ¨Valä¸Šï¼‰
5. Ablation Study
6. å®Œæ•´CLIå‚æ•°
"""

import torch
import argparse
import sys
import os
from pathlib import Path
import json
import numpy as np
import pandas as pd
from datetime import datetime
import random

# æ·»åŠ é¡¹ç›®è·¯å¾„
sys.path.insert(0, str(Path(__file__).parent.parent))

from src.models.gcn import create_gcn_model
from src.models.trainer2 import GCNTrainer
from src.data.feature_pipeline import NodeFeatureTransformer


def set_seed(seed: int):
    """å›ºå®šéšæœºç§å­"""
    random.seed(seed)
    np.random.seed(seed)
    torch.manual_seed(seed)
    if torch.cuda.is_available():
        torch.cuda.manual_seed(seed)
        torch.cuda.manual_seed_all(seed)
    torch.backends.cudnn.deterministic = True
    torch.backends.cudnn.benchmark = False


def parse_args():
    """è§£æå‘½ä»¤è¡Œå‚æ•°"""
    parser = argparse.ArgumentParser(description='GCNè®­ç»ƒ - å®Œæ•´é…ç½®')
    
    # æ•°æ®å‚æ•°
    parser.add_argument('--data-path', type=str, default='data/processed/homo_graph.pt',
                       help='æ•°æ®è·¯å¾„')
    
    # æ¨¡å‹å‚æ•°
    parser.add_argument('--architecture', type=str, default='default',
                       choices=['shallow', 'default', 'deep', 'very_deep'],
                       help='æ¨¡å‹æ¶æ„')
    parser.add_argument('--dropout', type=float, default=0.5,
                       help='æ ‡å‡†dropoutç‡')
    parser.add_argument('--edge-dropout', type=float, default=0.0,
                       help='è¾¹dropoutç‡ (0.0-0.5)')
    parser.add_argument('--feature-dropout', type=float, default=0.0,
                       help='ç‰¹å¾dropoutç‡ (0.0-0.5)')
    
    # ç‰¹å¾æ‰©å±•å‚æ•°
    parser.add_argument('--feat-augment', type=str, default='off',
                       choices=['on', 'off'],
                       help='æ˜¯å¦å¯ç”¨ç‰¹å¾æ‰©å±•')
    parser.add_argument('--topn', type=int, default=3,
                       help='Top-Né‡è¦ç‰¹å¾æ•°é‡')
    parser.add_argument('--bins', type=int, default=5,
                       help='åˆ†ç®±æ•°é‡')
    parser.add_argument('--add-interactions', type=str, default='on',
                       choices=['on', 'off'],
                       help='æ˜¯å¦æ·»åŠ äº¤äº’é¡¹')
    parser.add_argument('--importance-metric', type=str, default='aupr',
                       choices=['aupr', 'mi', 'lr_coef'],
                       help='ç‰¹å¾é‡è¦æ€§åº¦é‡')
    
    # è®­ç»ƒå‚æ•°
    parser.add_argument('--lr', type=float, default=0.01,
                       help='å­¦ä¹ ç‡')
    parser.add_argument('--weight-decay', type=float, default=5e-4,
                       help='æƒé‡è¡°å‡')
    parser.add_argument('--epochs', type=int, default=200,
                       help='æœ€å¤§è®­ç»ƒè½®æ•°')
    parser.add_argument('--patience', type=int, default=20,
                       help='æ—©åœpatience')
    
    # å…¶ä»–å‚æ•°
    parser.add_argument('--device', type=str, default='cpu',
                       choices=['cpu', 'cuda'],
                       help='è®¾å¤‡')
    parser.add_argument('--seed', type=int, default=42,
                       help='éšæœºç§å­')
    parser.add_argument('--save-dir', type=str, default='outputs/models',
                       help='æ¨¡å‹ä¿å­˜ç›®å½•')
    parser.add_argument('--eval-dir', type=str, default='outputs/evaluation',
                       help='è¯„ä¼°ç»“æœä¿å­˜ç›®å½•')
    
    # Ablation Study
    parser.add_argument('--run-ablation', action='store_true',
                       help='è¿è¡Œablation study')
    
    return parser.parse_args()


def print_config(args):
    """æ‰“å°é…ç½®"""
    print("\n" + "="*70)
    print("ğŸ“‹ è®­ç»ƒé…ç½®")
    print("="*70)
    
    print("\næ•°æ®:")
    print(f"   data_path: {args.data_path}")
    
    print("\næ¨¡å‹:")
    print(f"   architecture: {args.architecture}")
    print(f"   dropout: {args.dropout}")
    print(f"   edge_dropout: {args.edge_dropout}")
    print(f"   feature_dropout: {args.feature_dropout}")
    
    print("\nç‰¹å¾æ‰©å±•:")
    print(f"   feat_augment: {args.feat_augment}")
    if args.feat_augment == 'on':
        print(f"   topn: {args.topn}")
        print(f"   bins: {args.bins}")
        print(f"   add_interactions: {args.add_interactions}")
        print(f"   importance_metric: {args.importance_metric}")
    
    print("\nè®­ç»ƒ:")
    print(f"   lr: {args.lr}")
    print(f"   weight_decay: {args.weight_decay}")
    print(f"   epochs: {args.epochs}")
    print(f"   patience: {args.patience}")
    
    print("\nå…¶ä»–:")
    print(f"   device: {args.device}")
    print(f"   seed: {args.seed}")
    
    print("\n" + "="*70)


def train_single_config(args, config_name: str):
    """è®­ç»ƒå•ä¸ªé…ç½®"""
    
    print(f"\n{'='*70}")
    print(f"ğŸš€ è®­ç»ƒé…ç½®: {config_name}")
    print(f"{'='*70}")
    
    # å›ºå®šéšæœºç§å­
    set_seed(args.seed)
    
    # åŠ è½½æ•°æ®
    print("\n1. åŠ è½½æ•°æ®...")
    data = torch.load(args.data_path)
    print(f"   âœ“ èŠ‚ç‚¹: {data.num_nodes}")
    print(f"   âœ“ è¾¹: {data.num_edges}")
    print(f"   âœ“ ç‰¹å¾: {data.num_node_features}")
    print(f"   âœ“ è®­ç»ƒé›†: {data.train_mask.sum()}")
    print(f"   âœ“ éªŒè¯é›†: {data.val_mask.sum()}")
    print(f"   âœ“ æµ‹è¯•é›†: {data.test_mask.sum()}")
    
    # ç‰¹å¾æ‰©å±•
    feature_transformer = None
    if args.feat_augment == 'on':
        print("\n2. ç‰¹å¾æ‰©å±•...")
        feature_transformer = NodeFeatureTransformer(
            topn=args.topn,
            n_bins=args.bins,
            add_interactions=(args.add_interactions == 'on'),
            importance_metric=args.importance_metric,
            random_state=args.seed
        )
        
        # æ‹Ÿåˆå¹¶è½¬æ¢
        data.x = feature_transformer.fit_transform(data.x, data.y, data.train_mask)
        
        # ä¿å­˜è½¬æ¢å™¨
        transformer_path = Path(args.save_dir) / config_name / 'feature_transformer.pkl'
        transformer_path.parent.mkdir(parents=True, exist_ok=True)
        feature_transformer.save(str(transformer_path))
    
    # åˆ›å»ºæ¨¡å‹
    print("\n3. åˆ›å»ºæ¨¡å‹...")
    model = create_gcn_model(
        in_channels=data.num_node_features,
        architecture=args.architecture,
        dropout=args.dropout,
        edge_dropout=args.edge_dropout,
        feature_dropout=args.feature_dropout
    )
    
    num_params = sum(p.numel() for p in model.parameters())
    print(f"   âœ“ å‚æ•°é‡: {num_params:,}")
    print(f"   âœ“ Edge Dropout: {args.edge_dropout}")
    print(f"   âœ“ Feature Dropout: {args.feature_dropout}")
    
    # åˆ›å»ºè®­ç»ƒå™¨
    print("\n4. åˆ›å»ºè®­ç»ƒå™¨...")
    
    # è®¡ç®—pos_weight
    num_pos = data.y[data.train_mask].sum().item()
    num_neg = data.train_mask.sum().item() - num_pos
    pos_weight = num_neg / num_pos
    
    print(f"   âœ“ æ­£æ ·æœ¬: {num_pos} ({num_pos/(num_pos+num_neg)*100:.1f}%)")
    print(f"   âœ“ è´Ÿæ ·æœ¬: {num_neg} ({num_neg/(num_pos+num_neg)*100:.1f}%)")
    print(f"   âœ“ pos_weight: {pos_weight:.2f}")
    
    trainer = GCNTrainer(
        model=model,
        data=data,
        device=args.device,
        lr=args.lr,
        weight_decay=args.weight_decay,
        pos_weight=pos_weight
    )
    
    # è®­ç»ƒ
    print("\n5. å¼€å§‹è®­ç»ƒ...")
    save_dir = Path(args.save_dir) / config_name
    save_dir.mkdir(parents=True, exist_ok=True)
    
    history = trainer.train(
        epochs=args.epochs,
        early_stopping_patience=args.patience,
        save_dir=str(save_dir),
        verbose=True
        # æ³¨ï¼štrainerå·²é»˜è®¤ç›‘æ§val_aupr
    )
    
    # ä¿å­˜è®­ç»ƒå†å²
    history_path = save_dir / 'training_history.json'
    with open(history_path, 'w') as f:
        json.dump(history, f, indent=2)
    
    # è¯„ä¼°
    print("\n6. è¯„ä¼°...")
    eval_dir = Path(args.eval_dir) / config_name
    eval_dir.mkdir(parents=True, exist_ok=True)
    
    # åœ¨Valä¸Šæ‰¾æœ€ä¼˜é˜ˆå€¼
    print("\n   åœ¨éªŒè¯é›†ä¸Šæ‰«æé˜ˆå€¼...")
    val_probs, _, val_labels = trainer.predict(data.val_mask)
    
    best_threshold = 0.5
    best_f1 = 0.0
    threshold_results = []
    
    for t in np.arange(0.05, 0.75, 0.02):
        val_preds = (val_probs > t).astype(int)
        f1 = f1_score(val_labels, val_preds, zero_division=0)
        
        threshold_results.append({
            'threshold': float(t),
            'f1': float(f1)
        })
        
        if f1 > best_f1:
            best_f1 = f1
            best_threshold = t
    
    print(f"   âœ“ æœ€ä¼˜é˜ˆå€¼: {best_threshold:.2f} (Val F1={best_f1:.4f})")
    
    # åœ¨Testä¸Šä½¿ç”¨å›ºå®šé˜ˆå€¼
    print(f"\n   åœ¨æµ‹è¯•é›†ä¸Šè¯„ä¼° (é˜ˆå€¼={best_threshold:.2f})...")
    test_probs, _, test_labels = trainer.predict(data.test_mask)
    
    from src.models.trainer import compute_metrics
    test_metrics = compute_metrics(test_labels, test_probs, threshold=best_threshold)
    
    print(f"   âœ“ Test AUPR: {test_metrics['aupr']:.4f}")
    print(f"   âœ“ Test AUROC: {test_metrics['auroc']:.4f}")
    print(f"   âœ“ Test F1: {test_metrics['f1']:.4f}")
    print(f"   âœ“ Test Recall: {test_metrics['recall']:.4f}")
    print(f"   âœ“ Test Precision: {test_metrics['precision']:.4f}")
    
    # ä¿å­˜ç»“æœ
    results = {
        'config_name': config_name,
        'config': vars(args),
        'best_threshold': float(best_threshold),
        'best_val_f1': float(best_f1),
        'test_metrics': {k: float(v) for k, v in test_metrics.items()},
        'threshold_scan': threshold_results,
        'training_history': history
    }
    
    results_path = eval_dir / 'results.json'
    with open(results_path, 'w') as f:
        json.dump(results, f, indent=2)
    
    print(f"\n   âœ“ ç»“æœå·²ä¿å­˜: {results_path}")
    
    return results


def run_ablation_study(args):
    """è¿è¡ŒAblation Study"""
    
    print("\n" + "="*70)
    print("ğŸ§ª Ablation Study")
    print("="*70)
    
    # å®šä¹‰é…ç½®
    configs = [
        {
            'name': 'baseline',
            'edge_dropout': 0.0,
            'feature_dropout': 0.0,
            'feat_augment': 'off'
        },
        {
            'name': 'edge_dropout',
            'edge_dropout': 0.2,
            'feature_dropout': 0.0,
            'feat_augment': 'off'
        },
        {
            'name': 'feature_dropout',
            'edge_dropout': 0.0,
            'feature_dropout': 0.2,
            'feat_augment': 'off'
        },
        {
            'name': 'feat_augment',
            'edge_dropout': 0.0,
            'feature_dropout': 0.0,
            'feat_augment': 'on'
        },
        {
            'name': 'all_combined',
            'edge_dropout': 0.2,
            'feature_dropout': 0.2,
            'feat_augment': 'on'
        }
    ]
    
    all_results = []
    
    for config in configs:
        # æ›´æ–°args
        args_copy = argparse.Namespace(**vars(args))
        args_copy.edge_dropout = config['edge_dropout']
        args_copy.feature_dropout = config['feature_dropout']
        args_copy.feat_augment = config['feat_augment']
        
        # è®­ç»ƒ
        try:
            result = train_single_config(args_copy, config['name'])
            all_results.append(result)
        except Exception as e:
            print(f"\nâŒ é…ç½® {config['name']} è®­ç»ƒå¤±è´¥: {e}")
            continue
    
    # ç”Ÿæˆå¯¹æ¯”è¡¨
    print("\n" + "="*70)
    print("ğŸ“Š Ablation Study å¯¹æ¯”")
    print("="*70)
    
    comparison_data = []
    for result in all_results:
        comparison_data.append({
            'Config': result['config_name'],
            'Val_AUPR': result['training_history']['val_aupr'][-1] if 'val_aupr' in result['training_history'] else 0.0,
            'Test_AUPR': result['test_metrics']['aupr'],
            'Test_F1': result['test_metrics']['f1'],
            'Test_Recall': result['test_metrics']['recall'],
            'Test_Precision': result['test_metrics']['precision'],
            'Threshold': result['best_threshold']
        })
    
    df = pd.DataFrame(comparison_data)
    
    # æ‰“å°è¡¨æ ¼
    print("\n" + df.to_string(index=False))
    
    # ä¿å­˜CSV
    csv_path = Path(args.eval_dir) / 'ablation_summary.csv'
    df.to_csv(csv_path, index=False)
    print(f"\nâœ“ å¯¹æ¯”è¡¨å·²ä¿å­˜: {csv_path}")
    
    # ä¿å­˜å®Œæ•´ç»“æœ
    full_results_path = Path(args.eval_dir) / 'ablation_full_results.json'
    with open(full_results_path, 'w') as f:
        json.dump(all_results, f, indent=2)
    
    print(f"âœ“ å®Œæ•´ç»“æœå·²ä¿å­˜: {full_results_path}")
    
    print("\n" + "="*70)
    print("âœ… Ablation Study å®Œæˆï¼")
    print("="*70)


def main():
    """ä¸»å‡½æ•°"""
    args = parse_args()
    
    # æ‰“å°é…ç½®
    print_config(args)
    
    # åˆ›å»ºè¾“å‡ºç›®å½•
    Path(args.save_dir).mkdir(parents=True, exist_ok=True)
    Path(args.eval_dir).mkdir(parents=True, exist_ok=True)
    
    if args.run_ablation:
        # è¿è¡ŒAblation Study
        run_ablation_study(args)
    else:
        # å•æ¬¡è®­ç»ƒ
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        config_name = f"run_{timestamp}"
        train_single_config(args, config_name)


if __name__ == '__main__':
    # æ·»åŠ sklearnå¯¼å…¥
    from sklearn.metrics import f1_score
    main()